{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "import lmdb\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import skimage\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224])\n",
      "{'test': 5794, 'train': 5994}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lvlab/.tensorflow_pytorch/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/lvlab/.tensorflow_pytorch/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/home/lvlab/.tensorflow_pytorch/lib/python3.5/site-packages/skimage/util/dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "class Bird_Dataset_Local(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, train_file, root_dir, local_file, transform=None):\n",
    "        f = open(train_file, 'r')\n",
    "        self.train_list = f.readlines()\n",
    "        f.close()\n",
    "        self.local_points = np.load(local_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        line = self.train_list[idx]\n",
    "        img_dir_label = line.strip('\\n').split(' ')\n",
    "        img_dir = os.path.join(self.root_dir, img_dir_label[0])\n",
    "        image = io.imread(img_dir)\n",
    "        if len(image.shape) == 2:\n",
    "            image = image[:,:,np.newaxis]\n",
    "            image = np.tile(image, [1, 1, 3])\n",
    "            \n",
    "        vectors = self.local_points[idx]\n",
    "        x1, x2, y1, y2 = np.min(vectors[:, 0]), np.max(vectors[:, 0]), \\\n",
    "                        np.min(vectors[:, 1]), np.max(vectors[:, 1])\n",
    "        edge = 16\n",
    "        m1, m2, n1, n2 = int(np.maximum(x1 * 16 + 8 - edge, 0)), int(np.minimum(x2 * 16 + 8 + edge, 448)), \\\n",
    "                        int(np.maximum(y1 * 16 + 8 - edge, 0)), int(np.minimum(y2 * 16 + 8 + edge, 448))\n",
    "        \n",
    "        image = skimage.util.img_as_ubyte(transform.resize(image, (448, 448)))\n",
    "        image = image[m1:m2, n1:n2]\n",
    "\n",
    "        label = int(img_dir_label[1])\n",
    "        sample = {'image': image, 'label': label}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "data_transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize([224, 224]),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.486,0.499,0.432], [0.229,0.225,0.263])\n",
    "            ])\n",
    "\n",
    "root_dir = '/home/lvlab/Pytorch/images'\n",
    "train_file = '/home/lvlab/Pytorch/train.txt'\n",
    "test_file = '/home/lvlab/Pytorch/test.txt'\n",
    "local_train = '/home/lvlab/Pytorch/train_vectors_bird.npy'\n",
    "local_test = '/home/lvlab/Pytorch/test_vectors_bird.npy'\n",
    "\n",
    "image_datasets = {'train': Bird_Dataset_Local(train_file, root_dir, local_train, data_transform),\n",
    "                  'test': Bird_Dataset_Local(test_file, root_dir, local_test, data_transform)}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "\n",
    "print(image_datasets['train'][1]['image'].shape, image_datasets['test'][0]['image'].shape)\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "                \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            start_time = time.time()        \n",
    "            if epoch % 5 == 0 and phase == 'train':\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    lr = param_group['lr']\n",
    "                    print(\"***********************\")\n",
    "                    print(\"learning rate = %f\" % lr)\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for i_batch, sample_batched in enumerate(dataloaders[phase]):\n",
    "                inputs = sample_batched['image']\n",
    "                labels = sample_batched['label']\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                if i_batch % 50 == 0 and phase == 'train':\n",
    "                    print(\"Iteration %d, loss = %f\" % (i_batch, loss))\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            if phase == 'test':\n",
    "                scheduler.step(epoch_loss)\n",
    "                \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            cost_time = (time.time() - start_time)/60.0\n",
    "            print('{} 1 epoch time: {:.2f}min'.format(\n",
    "                phase, cost_time))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000250\n",
      "Iteration 0, loss = 0.210805\n",
      "Iteration 50, loss = 0.285740\n",
      "Iteration 100, loss = 0.192934\n",
      "Iteration 150, loss = 0.196217\n",
      "train Loss: 0.2166 Acc: 0.9328\n",
      "train 1 epoch time: 2.71min\n",
      "test Loss: 0.9534 Acc: 0.8086\n",
      "test 1 epoch time: 2.97min\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "Iteration 0, loss = 0.152200\n",
      "Iteration 50, loss = 0.090471\n",
      "Iteration 100, loss = 0.103536\n",
      "Iteration 150, loss = 0.292160\n",
      "train Loss: 0.2078 Acc: 0.9333\n",
      "train 1 epoch time: 3.38min\n",
      "test Loss: 0.9235 Acc: 0.8141\n",
      "test 1 epoch time: 3.05min\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "Iteration 0, loss = 0.081471\n",
      "Iteration 50, loss = 0.029022\n",
      "Iteration 100, loss = 0.110019\n",
      "Iteration 150, loss = 0.231945\n",
      "train Loss: 0.1823 Acc: 0.9426\n",
      "train 1 epoch time: 3.19min\n",
      "test Loss: 0.9343 Acc: 0.8217\n",
      "test 1 epoch time: 2.98min\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "Iteration 0, loss = 0.077488\n",
      "Iteration 50, loss = 0.304934\n",
      "Iteration 100, loss = 0.274917\n",
      "Iteration 150, loss = 0.100161\n",
      "train Loss: 0.1825 Acc: 0.9431\n",
      "train 1 epoch time: 3.26min\n",
      "test Loss: 0.9433 Acc: 0.8153\n",
      "test 1 epoch time: 3.14min\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "Iteration 0, loss = 0.105596\n",
      "Iteration 50, loss = 0.128906\n",
      "Iteration 100, loss = 0.183621\n",
      "Iteration 150, loss = 0.124996\n",
      "train Loss: 0.1842 Acc: 0.9416\n",
      "train 1 epoch time: 3.35min\n",
      "test Loss: 0.9601 Acc: 0.8158\n",
      "test 1 epoch time: 3.18min\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000125\n",
      "Iteration 0, loss = 0.113324\n",
      "Iteration 50, loss = 0.053478\n",
      "Iteration 100, loss = 0.099757\n",
      "Iteration 150, loss = 0.297492\n",
      "train Loss: 0.1701 Acc: 0.9466\n",
      "train 1 epoch time: 3.15min\n",
      "test Loss: 0.9675 Acc: 0.8138\n",
      "test 1 epoch time: 2.95min\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "Iteration 0, loss = 0.306470\n",
      "Iteration 50, loss = 0.062236\n",
      "Iteration 100, loss = 0.085479\n",
      "Iteration 150, loss = 0.130855\n",
      "train Loss: 0.1669 Acc: 0.9459\n",
      "train 1 epoch time: 3.11min\n",
      "test Loss: 0.9654 Acc: 0.8133\n",
      "test 1 epoch time: 2.90min\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "Iteration 0, loss = 0.205653\n",
      "Iteration 50, loss = 0.090640\n",
      "Iteration 100, loss = 0.122323\n",
      "Iteration 150, loss = 0.189256\n",
      "train Loss: 0.1674 Acc: 0.9419\n",
      "train 1 epoch time: 3.13min\n",
      "test Loss: 1.0017 Acc: 0.8141\n",
      "test 1 epoch time: 2.92min\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "Iteration 0, loss = 0.222537\n",
      "Iteration 50, loss = 0.053003\n",
      "Iteration 100, loss = 0.191779\n",
      "Iteration 150, loss = 0.253126\n",
      "train Loss: 0.1659 Acc: 0.9436\n",
      "train 1 epoch time: 3.23min\n",
      "test Loss: 0.9930 Acc: 0.8126\n",
      "test 1 epoch time: 3.14min\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "Iteration 0, loss = 0.090169\n",
      "Iteration 50, loss = 0.005300\n",
      "Iteration 100, loss = 0.336644\n",
      "Iteration 150, loss = 0.181909\n",
      "train Loss: 0.1699 Acc: 0.9456\n",
      "train 1 epoch time: 3.33min\n",
      "test Loss: 0.9801 Acc: 0.8108\n",
      "test 1 epoch time: 3.10min\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000125\n",
      "Iteration 0, loss = 0.047987\n",
      "Iteration 50, loss = 0.165615\n",
      "Iteration 100, loss = 0.032885\n",
      "Iteration 150, loss = 0.113431\n",
      "train Loss: 0.1805 Acc: 0.9409\n",
      "train 1 epoch time: 3.37min\n",
      "test Loss: 0.9945 Acc: 0.8158\n",
      "test 1 epoch time: 3.03min\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "Iteration 0, loss = 0.296920\n",
      "Iteration 50, loss = 0.195716\n",
      "Iteration 100, loss = 0.244193\n",
      "Iteration 150, loss = 0.127539\n",
      "train Loss: 0.1565 Acc: 0.9494\n",
      "train 1 epoch time: 3.12min\n",
      "test Loss: 0.9843 Acc: 0.8157\n",
      "test 1 epoch time: 2.95min\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "Iteration 0, loss = 0.036301\n",
      "Iteration 50, loss = 0.147816\n",
      "Iteration 100, loss = 0.202607\n",
      "Iteration 150, loss = 0.307605\n",
      "train Loss: 0.1643 Acc: 0.9444\n",
      "train 1 epoch time: 3.04min\n",
      "test Loss: 0.9505 Acc: 0.8145\n",
      "test 1 epoch time: 2.78min\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "Iteration 0, loss = 0.218316\n",
      "Iteration 50, loss = 0.168311\n",
      "Iteration 100, loss = 0.041869\n",
      "Iteration 150, loss = 0.016650\n",
      "train Loss: 0.1691 Acc: 0.9463\n",
      "train 1 epoch time: 3.15min\n",
      "test Loss: 0.9765 Acc: 0.8150\n",
      "test 1 epoch time: 2.87min\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "Iteration 0, loss = 0.125189\n",
      "Iteration 50, loss = 0.328002\n",
      "Iteration 100, loss = 0.044995\n",
      "Iteration 150, loss = 0.069166\n",
      "train Loss: 0.1662 Acc: 0.9463\n",
      "train 1 epoch time: 3.17min\n",
      "test Loss: 0.9720 Acc: 0.8172\n",
      "test 1 epoch time: 3.00min\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000063\n",
      "Iteration 0, loss = 0.142201\n",
      "Iteration 50, loss = 0.089125\n",
      "Iteration 100, loss = 0.282510\n",
      "Iteration 150, loss = 0.138319\n",
      "train Loss: 0.1404 Acc: 0.9560\n",
      "train 1 epoch time: 3.20min\n",
      "test Loss: 1.0018 Acc: 0.8164\n",
      "test 1 epoch time: 3.17min\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "Iteration 0, loss = 0.172972\n",
      "Iteration 50, loss = 0.167723\n",
      "Iteration 100, loss = 0.250256\n",
      "Iteration 150, loss = 0.180162\n",
      "train Loss: 0.1411 Acc: 0.9543\n",
      "train 1 epoch time: 3.84min\n",
      "test Loss: 0.9859 Acc: 0.8176\n",
      "test 1 epoch time: 3.63min\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "Iteration 0, loss = 0.148466\n",
      "Iteration 50, loss = 0.055836\n",
      "Iteration 100, loss = 0.288447\n",
      "Iteration 150, loss = 0.204835\n",
      "train Loss: 0.1431 Acc: 0.9528\n",
      "train 1 epoch time: 3.84min\n",
      "test Loss: 0.9970 Acc: 0.8148\n",
      "test 1 epoch time: 3.58min\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "Iteration 0, loss = 0.171783\n",
      "Iteration 50, loss = 0.053058\n",
      "Iteration 100, loss = 0.175496\n",
      "Iteration 150, loss = 0.227764\n",
      "train Loss: 0.1529 Acc: 0.9516\n",
      "train 1 epoch time: 3.15min\n",
      "test Loss: 0.9873 Acc: 0.8169\n",
      "test 1 epoch time: 2.97min\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "Iteration 0, loss = 0.057014\n",
      "Iteration 50, loss = 0.170844\n",
      "Iteration 100, loss = 0.065405\n",
      "Iteration 150, loss = 0.190187\n",
      "train Loss: 0.1562 Acc: 0.9503\n",
      "train 1 epoch time: 3.12min\n",
      "test Loss: 0.9891 Acc: 0.8157\n",
      "test 1 epoch time: 3.24min\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000063\n",
      "Iteration 0, loss = 0.001317\n",
      "Iteration 50, loss = 0.284590\n",
      "Iteration 100, loss = 0.066602\n",
      "Iteration 150, loss = 0.082944\n",
      "train Loss: 0.1460 Acc: 0.9530\n",
      "train 1 epoch time: 3.29min\n",
      "test Loss: 0.9825 Acc: 0.8146\n",
      "test 1 epoch time: 2.83min\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "Iteration 0, loss = 0.093700\n",
      "Iteration 50, loss = 0.038374\n",
      "Iteration 100, loss = 0.038211\n",
      "Iteration 150, loss = 0.255811\n",
      "train Loss: 0.1429 Acc: 0.9540\n",
      "train 1 epoch time: 3.12min\n",
      "test Loss: 0.9897 Acc: 0.8169\n",
      "test 1 epoch time: 2.68min\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "Iteration 0, loss = 0.162897\n",
      "Iteration 50, loss = 0.143735\n",
      "Iteration 100, loss = 0.198882\n",
      "Iteration 150, loss = 0.130454\n",
      "train Loss: 0.1335 Acc: 0.9586\n",
      "train 1 epoch time: 2.38min\n",
      "test Loss: 1.0136 Acc: 0.8158\n",
      "test 1 epoch time: 2.35min\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "Iteration 0, loss = 0.104453\n",
      "Iteration 50, loss = 0.035507\n",
      "Iteration 100, loss = 0.113449\n",
      "Iteration 150, loss = 0.146307\n",
      "train Loss: 0.1351 Acc: 0.9555\n",
      "train 1 epoch time: 2.56min\n",
      "test Loss: 1.0230 Acc: 0.8155\n",
      "test 1 epoch time: 2.48min\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "Iteration 0, loss = 0.026168\n",
      "Iteration 50, loss = 0.284847\n",
      "Iteration 100, loss = 0.055563\n",
      "Iteration 150, loss = 0.037827\n",
      "train Loss: 0.1376 Acc: 0.9556\n",
      "train 1 epoch time: 2.55min\n",
      "test Loss: 1.0038 Acc: 0.8198\n",
      "test 1 epoch time: 2.45min\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000031\n",
      "Iteration 0, loss = 0.186307\n",
      "Iteration 50, loss = 0.163037\n",
      "Iteration 100, loss = 0.253502\n",
      "Iteration 150, loss = 0.032621\n",
      "train Loss: 0.1236 Acc: 0.9596\n",
      "train 1 epoch time: 2.50min\n",
      "test Loss: 1.0188 Acc: 0.8131\n",
      "test 1 epoch time: 2.50min\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "Iteration 0, loss = 0.121405\n",
      "Iteration 50, loss = 0.321445\n",
      "Iteration 100, loss = 0.296862\n",
      "Iteration 150, loss = 0.344018\n",
      "train Loss: 0.1332 Acc: 0.9536\n",
      "train 1 epoch time: 2.63min\n",
      "test Loss: 1.0187 Acc: 0.8167\n",
      "test 1 epoch time: 2.47min\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "Iteration 0, loss = 0.119246\n",
      "Iteration 50, loss = 0.201797\n",
      "Iteration 100, loss = 0.079170\n",
      "Iteration 150, loss = 0.060419\n",
      "train Loss: 0.1364 Acc: 0.9561\n",
      "train 1 epoch time: 2.66min\n",
      "test Loss: 1.0120 Acc: 0.8152\n",
      "test 1 epoch time: 2.43min\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "Iteration 0, loss = 0.107075\n",
      "Iteration 50, loss = 0.077478\n",
      "Iteration 100, loss = 0.123618\n",
      "Iteration 150, loss = 0.188168\n",
      "train Loss: 0.1444 Acc: 0.9521\n",
      "train 1 epoch time: 2.67min\n",
      "test Loss: 0.9915 Acc: 0.8164\n",
      "test 1 epoch time: 2.41min\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "Iteration 0, loss = 0.132590\n",
      "Iteration 50, loss = 0.100737\n",
      "Iteration 100, loss = 0.057635\n",
      "Iteration 150, loss = 0.208292\n",
      "train Loss: 0.1373 Acc: 0.9546\n",
      "train 1 epoch time: 2.77min\n",
      "test Loss: 0.9949 Acc: 0.8158\n",
      "test 1 epoch time: 2.94min\n",
      "\n",
      "Training complete in 179m 5s\n",
      "Best val Acc: 0.821712\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import time\n",
    "import warnings\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "local_net = models.vgg16(pretrained=True)\n",
    "\n",
    "local_net.classifier = nn.Sequential(*list(local_net.classifier.children())[:1])\n",
    "local_net.features[30] = nn.AvgPool2d(kernel_size=14, stride=1, padding=0)\n",
    "local_net.features.add_module('31', nn.Dropout(0.8)) \n",
    "local_net.classifier[0] = nn.Linear(in_features=512, out_features=200, bias=True)\n",
    "\n",
    "local_net = local_net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "# optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "optimizer_ft = optim.SGD(local_net.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, mode='min', factor=0.5, patience=10)\n",
    "\n",
    "model_best = train_model(local_net, criterion, optimizer_ft,\n",
    "                         exp_lr_scheduler, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_best, \"object_bird\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
