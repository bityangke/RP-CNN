{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import skimage\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, transform\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.load(\"train_vectors_car.npy\")\n",
    "test_vectors = np.load(\"test_vectors_car.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pro_select(vectors, probs, num):\n",
    "    points = np.zeros((num, 2))\n",
    "    core_point = np.zeros((1, 2))\n",
    "    for i in range(num):\n",
    "        x = random.uniform(0, 1)\n",
    "        cumprob = 0.0\n",
    "        k = -1\n",
    "        while x > cumprob:\n",
    "            k += 1\n",
    "            cumprob += probs[k]\n",
    "        points[i, 0], points[i, 1] = vectors[k, 0], vectors[k, 1]\n",
    "        \n",
    "        adj_list = []\n",
    "        core_point[0, 0], core_point[0, 1] = vectors[k, 0], vectors[k, 1]\n",
    "        dis = np.sum(pow(vectors - core_point, 2), axis=1)\n",
    "        for j in range(len(dis)):\n",
    "            if dis[j] <= 8:\n",
    "                adj_list.append(j)\n",
    "        for j in range(len(adj_list)):\n",
    "            probs[adj_list[j]] /= 100.0\n",
    "            \n",
    "        probs[k] = 0\n",
    "        probs = probs/np.sum(probs)\n",
    "        \n",
    "    return points\n",
    "\n",
    "class Bird_Test_Process(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, train_file, root_dir, train_vectors, num, transform=None):\n",
    "        f = open(train_file, 'r')\n",
    "        self.train_list = f.readlines()\n",
    "        f.close()\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.train_vectors = train_vectors\n",
    "        self.part_num = num\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        line = self.train_list[idx]\n",
    "        img_dir_label = line.strip('\\n').split(' ')\n",
    "        img_dir = os.path.join(self.root_dir, img_dir_label[0])\n",
    "        image = io.imread(img_dir)\n",
    "        if len(image.shape) == 2:\n",
    "            image = image[:,:,np.newaxis]\n",
    "            image = np.tile(image, [1, 1, 3])\n",
    "            \n",
    "        image = skimage.util.img_as_ubyte(transform.resize(image, (448, 448))) \n",
    "        label = int(img_dir_label[1])\n",
    "        sample = {}\n",
    "        \n",
    "        vectors = self.train_vectors[idx]\n",
    "\n",
    "        points = pro_select(vectors[:, :2].astype(int), copy.deepcopy(vectors[:, 3]), self.part_num)\n",
    "\n",
    "        points1 = pro_select(vectors[:, :2].astype(int), copy.deepcopy(vectors[:, 3]), self.part_num)\n",
    "\n",
    "        points2 = pro_select(vectors[:, :2].astype(int), copy.deepcopy(vectors[:, 3]), self.part_num)\n",
    "\n",
    "        for i in range(self.part_num):\n",
    "            x, y = points[i][0] * 16 + 8, points[i][1] * 16 + 8\n",
    "            l = random.randint(46, 98)\n",
    "#             l = 46\n",
    "            m1, m2, n1, n2 = int(np.maximum(0, x - l)), int(np.minimum(448, x + l)), \\\n",
    "                            int(np.maximum(0, y - l)), int(np.minimum(448, y + l))\n",
    "            sample['image%d' % i] = image[m1:m2, n1:n2]\n",
    "            x1, y1 = points1[i][0] * 16 + 8, points1[i][1] * 16 + 8\n",
    "            l1 = random.randint(46, 98)\n",
    "            m1, m2, n1, n2 = int(np.maximum(0, x1 - l1)), int(np.minimum(448, x1 + l1)), \\\n",
    "                            int(np.maximum(0, y1 - l1)), int(np.minimum(448, y1 + l1))\n",
    "            sample['s_image%d' % i] = image[m1:m2, n1:n2]\n",
    "            x2, y2 = points2[i][0] * 16 + 8, points2[i][1] * 16 + 8\n",
    "            l2 = random.randint(46, 98)\n",
    "            m1, m2, n1, n2 = int(np.maximum(0, x2 - l2)), int(np.minimum(448, x2 + l2)), \\\n",
    "                            int(np.maximum(0, y2 - l2)), int(np.minimum(448, y2 + l2))\n",
    "            sample['t_image%d' % i] = image[m1:m2, n1:n2]\n",
    "            \n",
    "        sample['label'] = label\n",
    "\n",
    "        if self.transform:\n",
    "            for i in range(self.part_num):\n",
    "                sample['image%d' % i] = self.transform(sample['image%d' % i])\n",
    "                sample['s_image%d' % i] = self.transform(sample['s_image%d' % i])\n",
    "                sample['t_image%d' % i] = self.transform(sample['t_image%d' % i])\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class Bird_Dataset_Process(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, train_file, root_dir, train_vectors, num, transform=None):\n",
    "        f = open(train_file, 'r')\n",
    "        self.train_list = f.readlines()\n",
    "        f.close()\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.train_vectors = train_vectors\n",
    "        self.part_num = num\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        line = self.train_list[idx]\n",
    "        img_dir_label = line.strip('\\n').split(' ')\n",
    "        img_dir = os.path.join(self.root_dir, img_dir_label[0])\n",
    "        image = io.imread(img_dir)\n",
    "        if len(image.shape) == 2:\n",
    "            image = image[:,:,np.newaxis]\n",
    "            image = np.tile(image, [1, 1, 3])\n",
    "            \n",
    "        image = skimage.util.img_as_ubyte(transform.resize(image, (448, 448))) \n",
    "        label = int(img_dir_label[1])\n",
    "        sample = {}\n",
    "        \n",
    "        vectors = self.train_vectors[idx]\n",
    "        points = pro_select(vectors[:, :2].astype(int), vectors[:, 3], self.part_num)\n",
    "        for i in range(self.part_num):\n",
    "            x, y = points[i][0] * 16 + 8, points[i][1] * 16 + 8\n",
    "            l = random.randint(46, 98)\n",
    "#             l = 46\n",
    "            m1, m2, n1, n2 = int(np.maximum(0, x - l)), int(np.minimum(448, x + l)), \\\n",
    "                            int(np.maximum(0, y - l)), int(np.minimum(448, y + l))\n",
    "            sample['image%d' % i] = image[m1:m2, n1:n2]\n",
    "        \n",
    "        sample['label'] = label\n",
    "\n",
    "        if self.transform:\n",
    "            for i in range(self.part_num):\n",
    "                sample['image%d' % i] = self.transform(sample['image%d' % i])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinsir/.tensorflow/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/xinsir/.tensorflow/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/home/xinsir/.tensorflow/lib/python3.5/site-packages/skimage/util/dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image1': tensor([[[-0.2297, -0.2700, -0.3237,  ...,  0.5224,  0.5224,  0.5224],\n",
      "         [-0.2969, -0.3237, -0.3775,  ...,  0.5224,  0.5224,  0.5224],\n",
      "         [-0.3775, -0.3909, -0.4312,  ...,  0.5224,  0.5224,  0.5224],\n",
      "         ...,\n",
      "         [ 0.0926,  0.1195, -0.0283,  ...,  0.7238,  0.7238,  0.7104],\n",
      "         [-0.0551,  0.0389, -0.0417,  ...,  0.7238,  0.7238,  0.7104],\n",
      "         [-0.2297, -0.1223, -0.1223,  ...,  0.7238,  0.7238,  0.7104]],\n",
      "\n",
      "        [[-0.1927, -0.2197, -0.2601,  ...,  0.7102,  0.7102,  0.7102],\n",
      "         [-0.2601, -0.2736, -0.3140,  ...,  0.7102,  0.7102,  0.7102],\n",
      "         [-0.3409, -0.3544, -0.3814,  ...,  0.7102,  0.7102,  0.7102],\n",
      "         ...,\n",
      "         [-0.0579, -0.0445, -0.1927,  ...,  0.7911,  0.7911,  0.7776],\n",
      "         [-0.2062, -0.1253, -0.2062,  ...,  0.7911,  0.7911,  0.7776],\n",
      "         [-0.3949, -0.2870, -0.2870,  ...,  0.7911,  0.7911,  0.7911]],\n",
      "\n",
      "        [[-0.1315, -0.1446, -0.1839,  ...,  1.1276,  1.1276,  1.1276],\n",
      "         [-0.1971, -0.2102, -0.2364,  ...,  1.1145,  1.1145,  1.1145],\n",
      "         [-0.2758, -0.2889, -0.2889,  ...,  1.1145,  1.1014,  1.1014],\n",
      "         ...,\n",
      "         [-0.2889, -0.2758, -0.4331,  ...,  1.0883,  1.0883,  1.1014],\n",
      "         [-0.4331, -0.3544, -0.4463,  ...,  1.0883,  1.0883,  1.0883],\n",
      "         [-0.6168, -0.5118, -0.5118,  ...,  1.0752,  1.0752,  1.0752]]]), 'label': 1, 's_image1': tensor([[[ 0.7641,  0.7507,  0.7104,  ..., -1.1967, -1.1161, -1.0624],\n",
      "         [ 0.7641,  0.7507,  0.7238,  ..., -1.1967, -1.1027, -1.0490],\n",
      "         [ 0.7641,  0.7641,  0.7641,  ..., -1.1833, -1.0758, -1.0087],\n",
      "         ...,\n",
      "         [-0.4446, -0.4446, -0.4312,  ...,  1.0596,  1.0461,  1.0327],\n",
      "         [-0.4312, -0.4312, -0.4177,  ...,  1.1133,  1.1401,  1.1401],\n",
      "         [-0.4177, -0.4177, -0.4043,  ...,  1.1536,  1.1939,  1.2073]],\n",
      "\n",
      "        [[ 0.8315,  0.8315,  0.8180,  ..., -1.2573, -1.1630, -1.1091],\n",
      "         [ 0.8315,  0.8315,  0.8315,  ..., -1.2573, -1.1495, -1.0956],\n",
      "         [ 0.8315,  0.8450,  0.8584,  ..., -1.2439, -1.1226, -1.0552],\n",
      "         ...,\n",
      "         [-0.4622, -0.4622, -0.4757,  ...,  0.9528,  0.9393,  0.9258],\n",
      "         [-0.4488, -0.4488, -0.4622,  ...,  1.0067,  1.0336,  1.0336],\n",
      "         [-0.4353, -0.4488, -0.4622,  ...,  1.0471,  1.0875,  1.1010]],\n",
      "\n",
      "        [[ 1.1014,  1.1014,  1.0883,  ..., -1.3512, -1.2725, -1.2201],\n",
      "         [ 1.1014,  1.1014,  1.1014,  ..., -1.3512, -1.2594, -1.2070],\n",
      "         [ 1.1014,  1.1145,  1.1276,  ..., -1.3381, -1.2332, -1.1676],\n",
      "         ...,\n",
      "         [-0.8922, -0.8660, -0.8266,  ...,  0.9178,  0.8915,  0.8784],\n",
      "         [-0.8791, -0.8528, -0.8135,  ...,  0.9702,  0.9833,  0.9965],\n",
      "         [-0.8660, -0.8528, -0.8135,  ...,  1.0096,  1.0489,  1.0620]]]), 'image0': tensor([[[ 0.6970,  0.6970,  0.6970,  ..., -0.5789, -0.5789, -0.5789],\n",
      "         [ 0.6970,  0.6970,  0.6970,  ..., -0.5789, -0.5789, -0.5789],\n",
      "         [ 0.6970,  0.6970,  0.6970,  ..., -0.5789, -0.5789, -0.5789],\n",
      "         ...,\n",
      "         [-0.0417, -0.1089, -0.2163,  ..., -1.2101, -1.2235, -1.2370],\n",
      "         [-0.0551, -0.1223, -0.2297,  ..., -1.2370, -1.2504, -1.2638],\n",
      "         [-0.1223, -0.1894, -0.2969,  ..., -1.2638, -1.2773, -1.2773]],\n",
      "\n",
      "        [[ 0.8315,  0.8315,  0.8315,  ..., -0.4892, -0.4892, -0.4892],\n",
      "         [ 0.8315,  0.8315,  0.8315,  ..., -0.4892, -0.4892, -0.4892],\n",
      "         [ 0.8315,  0.8315,  0.8315,  ..., -0.4892, -0.4892, -0.4892],\n",
      "         ...,\n",
      "         [-0.1523, -0.2331, -0.3409,  ..., -1.2169, -1.2439, -1.2573],\n",
      "         [-0.1658, -0.2466, -0.3544,  ..., -1.2304, -1.2573, -1.2708],\n",
      "         [-0.2331, -0.3140, -0.4218,  ..., -1.2573, -1.2708, -1.2843]],\n",
      "\n",
      "        [[ 1.1670,  1.1670,  1.1670,  ..., -0.3413, -0.3413, -0.3413],\n",
      "         [ 1.1670,  1.1670,  1.1670,  ..., -0.3413, -0.3413, -0.3413],\n",
      "         [ 1.1670,  1.1670,  1.1670,  ..., -0.3413, -0.3413, -0.3413],\n",
      "         ...,\n",
      "         [-0.3544, -0.4200, -0.5250,  ..., -1.1807, -1.1938, -1.2070],\n",
      "         [-0.3676, -0.4331, -0.5381,  ..., -1.2070, -1.2201, -1.2332],\n",
      "         [-0.4331, -0.4987, -0.6036,  ..., -1.2332, -1.2463, -1.2463]]]), 't_image1': tensor([[[ 0.6164,  0.6164,  0.6298,  ...,  0.5224,  0.3209,  0.1329],\n",
      "         [ 0.6164,  0.6164,  0.6298,  ...,  0.5224,  0.3209,  0.1329],\n",
      "         [ 0.6298,  0.6298,  0.6432,  ...,  0.5224,  0.3209,  0.1329],\n",
      "         ...,\n",
      "         [-0.7535, -0.7535, -0.7401,  ...,  0.6701,  0.4552,  0.2538],\n",
      "         [-0.7535, -0.7535, -0.7401,  ...,  0.6701,  0.4552,  0.2538],\n",
      "         [-0.7535, -0.7535, -0.7401,  ...,  0.6701,  0.4552,  0.2538]],\n",
      "\n",
      "        [[ 0.5215,  0.5215,  0.5215,  ...,  0.7102,  0.4946,  0.2924],\n",
      "         [ 0.5215,  0.5215,  0.5215,  ...,  0.7102,  0.4946,  0.2924],\n",
      "         [ 0.5215,  0.5215,  0.5350,  ...,  0.7102,  0.4946,  0.2790],\n",
      "         ...,\n",
      "         [-0.7587, -0.7587, -0.7452,  ...,  0.7776,  0.5620,  0.3463],\n",
      "         [-0.7587, -0.7587, -0.7452,  ...,  0.7776,  0.5620,  0.3463],\n",
      "         [-0.7587, -0.7587, -0.7452,  ...,  0.7776,  0.5620,  0.3463]],\n",
      "\n",
      "        [[ 0.1439,  0.1439,  0.1571,  ...,  1.1276,  0.8784,  0.6292],\n",
      "         [ 0.1439,  0.1439,  0.1571,  ...,  1.1276,  0.8784,  0.6292],\n",
      "         [ 0.1308,  0.1439,  0.1571,  ...,  1.1276,  0.8784,  0.6292],\n",
      "         ...,\n",
      "         [-0.8004, -0.7873, -0.7741,  ...,  1.0358,  0.7997,  0.5636],\n",
      "         [-0.7873, -0.7873, -0.7741,  ...,  1.0358,  0.7997,  0.5636],\n",
      "         [-0.7873, -0.7873, -0.7741,  ...,  1.0358,  0.7997,  0.5636]]]), 's_image0': tensor([[[ 0.0657,  0.0389,  0.0523,  ...,  0.5089,  0.4552,  0.4015],\n",
      "         [ 0.0657,  0.0389,  0.0254,  ...,  0.5089,  0.4552,  0.3881],\n",
      "         [ 0.0792,  0.0389,  0.0120,  ...,  0.5089,  0.4552,  0.3746],\n",
      "         ...,\n",
      "         [-1.4787, -1.4787, -1.4519,  ..., -0.6863, -0.6863, -0.7132],\n",
      "         [-1.4921, -1.4653, -1.4116,  ..., -0.6998, -0.6998, -0.7266],\n",
      "         [-1.3578, -1.3176, -1.2638,  ..., -0.6998, -0.7132, -0.7266]],\n",
      "\n",
      "        [[ 0.4676,  0.4272,  0.4002,  ...,  0.5081,  0.4811,  0.4272],\n",
      "         [ 0.4811,  0.4137,  0.3733,  ...,  0.5215,  0.4811,  0.4137],\n",
      "         [ 0.4811,  0.4137,  0.3598,  ...,  0.5350,  0.4946,  0.4002],\n",
      "         ...,\n",
      "         [-1.4999, -1.4999, -1.4729,  ..., -0.7857, -0.7991, -0.8261],\n",
      "         [-1.5134, -1.4729, -1.4190,  ..., -0.7991, -0.8126, -0.8396],\n",
      "         [-1.3786, -1.3247, -1.2708,  ..., -0.7991, -0.8126, -0.8396]],\n",
      "\n",
      "        [[ 0.7473,  0.6817,  0.6292,  ...,  0.1964,  0.1833,  0.1571],\n",
      "         [ 0.7473,  0.6686,  0.6161,  ...,  0.1964,  0.1702,  0.1308],\n",
      "         [ 0.7341,  0.6555,  0.5899,  ...,  0.1833,  0.1571,  0.1177],\n",
      "         ...,\n",
      "         [-1.4824, -1.4824, -1.4562,  ..., -0.7741, -0.8135, -0.8397],\n",
      "         [-1.4955, -1.4693, -1.4168,  ..., -0.7873, -0.8266, -0.8528],\n",
      "         [-1.3644, -1.3250, -1.2725,  ..., -0.7873, -0.8135, -0.8397]]]), 't_image3': tensor([[[-0.5118, -0.5252, -0.5386,  ...,  0.8581,  0.8447,  0.7775],\n",
      "         [-0.5118, -0.5118, -0.5252,  ...,  0.8850,  0.8715,  0.8178],\n",
      "         [-0.5386, -0.5386, -0.5520,  ...,  0.8178,  0.8581,  0.8447],\n",
      "         ...,\n",
      "         [-1.3847, -1.3981, -1.3713,  ..., -0.0686,  0.0657,  0.0926],\n",
      "         [-1.4250, -1.4384, -1.4116,  ..., -0.0283,  0.0657,  0.0792],\n",
      "         [-1.4519, -1.4653, -1.4384,  ..., -0.0014,  0.0523,  0.0792]],\n",
      "\n",
      "        [[-0.4757, -0.4757, -0.4892,  ...,  0.6832,  0.6698,  0.6024],\n",
      "         [-0.4757, -0.4757, -0.4892,  ...,  0.6967,  0.6967,  0.6428],\n",
      "         [-0.5027, -0.5027, -0.5161,  ...,  0.6293,  0.6832,  0.6698],\n",
      "         ...,\n",
      "         [-1.3517, -1.3651, -1.3382,  ..., -0.0579,  0.1038,  0.1307],\n",
      "         [-1.3786, -1.3921, -1.3651,  ..., -0.0175,  0.1038,  0.1307],\n",
      "         [-1.3921, -1.4190, -1.3921,  ...,  0.0229,  0.1038,  0.1307]],\n",
      "\n",
      "        [[-0.3282, -0.3282, -0.3282,  ...,  0.4456,  0.4063,  0.3407],\n",
      "         [-0.3282, -0.3151, -0.3282,  ...,  0.4194,  0.3931,  0.3276],\n",
      "         [-0.3544, -0.3413, -0.3544,  ...,  0.3144,  0.3407,  0.3144],\n",
      "         ...,\n",
      "         [-1.2988, -1.3119, -1.2857,  ...,  0.0521,  0.2226,  0.2751],\n",
      "         [-1.3250, -1.3381, -1.3119,  ...,  0.0784,  0.2226,  0.2620],\n",
      "         [-1.3512, -1.3644, -1.3381,  ...,  0.1177,  0.2226,  0.2751]]]), 'image2': tensor([[[-0.3909, -0.4446, -0.6058,  ...,  0.0389,  0.0254,  0.0254],\n",
      "         [-0.4043, -0.4580, -0.6058,  ...,  0.0254,  0.0120,  0.0120],\n",
      "         [-0.4446, -0.4983, -0.6192,  ..., -0.0148, -0.0148, -0.0148],\n",
      "         ...,\n",
      "         [-0.9549, -0.9684, -0.9818,  ..., -0.2566, -0.3237, -0.3506],\n",
      "         [-0.9952, -0.9952, -1.0087,  ..., -0.2432, -0.3237, -0.3640],\n",
      "         [-1.0087, -1.0087, -1.0221,  ..., -0.2432, -0.3237, -0.3640]],\n",
      "\n",
      "        [[-0.5970, -0.6509, -0.7991,  ..., -0.2466, -0.2466, -0.2466],\n",
      "         [-0.5970, -0.6509, -0.7991,  ..., -0.2601, -0.2601, -0.2601],\n",
      "         [-0.6105, -0.6644, -0.7857,  ..., -0.2870, -0.2870, -0.2870],\n",
      "         ...,\n",
      "         [-1.0417, -1.0552, -1.0687,  ..., -0.4353, -0.5027, -0.5296],\n",
      "         [-1.0821, -1.0821, -1.0956,  ..., -0.4218, -0.5027, -0.5296],\n",
      "         [-1.0956, -1.0956, -1.1091,  ..., -0.4218, -0.5027, -0.5296]],\n",
      "\n",
      "        [[-0.6430, -0.6955, -0.8397,  ..., -0.4463, -0.4331, -0.4331],\n",
      "         [-0.6561, -0.6955, -0.8397,  ..., -0.4594, -0.4463, -0.4463],\n",
      "         [-0.6692, -0.7086, -0.8397,  ..., -0.4856, -0.4725, -0.4725],\n",
      "         ...,\n",
      "         [-0.9840, -0.9971, -1.0102,  ..., -0.6168, -0.6692, -0.6955],\n",
      "         [-1.0233, -1.0233, -1.0365,  ..., -0.6036, -0.6692, -0.6955],\n",
      "         [-1.0365, -1.0365, -1.0496,  ..., -0.6036, -0.6692, -0.6955]]]), 't_image2': tensor([[[-0.3640, -0.5789, -0.7401,  ..., -0.1223, -0.0686, -0.0417],\n",
      "         [-0.4446, -0.6863, -0.8609,  ..., -0.1760, -0.1223, -0.0820],\n",
      "         [-0.5520, -0.8072, -0.9415,  ..., -0.1760, -0.1357, -0.0820],\n",
      "         ...,\n",
      "         [ 0.9790,  0.9790,  0.9118,  ..., -0.8878, -0.8072, -0.7938],\n",
      "         [ 1.0058,  1.0327,  1.0327,  ..., -0.8878, -0.8206, -0.7938],\n",
      "         [ 1.0327,  1.0864,  1.1401,  ..., -0.8744, -0.8206, -0.8072]],\n",
      "\n",
      "        [[-0.2062, -0.4218, -0.5835,  ..., -0.1658, -0.1119, -0.0579],\n",
      "         [-0.3005, -0.5431, -0.7183,  ..., -0.2197, -0.1523, -0.0984],\n",
      "         [-0.4218, -0.6644, -0.8261,  ..., -0.2197, -0.1523, -0.0984],\n",
      "         ...,\n",
      "         [ 0.9258,  0.9258,  0.8584,  ..., -0.9204, -0.8396, -0.8261],\n",
      "         [ 0.9528,  0.9797,  0.9797,  ..., -0.9069, -0.8396, -0.8261],\n",
      "         [ 0.9797,  1.0336,  1.0875,  ..., -0.9069, -0.8396, -0.8261]],\n",
      "\n",
      "        [[-0.1315, -0.3413, -0.5118,  ..., -0.3282, -0.2626, -0.2102],\n",
      "         [-0.2233, -0.4725, -0.6430,  ..., -0.3807, -0.3151, -0.2364],\n",
      "         [-0.3544, -0.6036, -0.7610,  ..., -0.3807, -0.3151, -0.2364],\n",
      "         ...,\n",
      "         [ 0.7997,  0.8128,  0.7341,  ..., -0.8266, -0.7741, -0.7610],\n",
      "         [ 0.8260,  0.8522,  0.8522,  ..., -0.8266, -0.7741, -0.7610],\n",
      "         [ 0.8391,  0.8915,  0.9440,  ..., -0.8397, -0.7873, -0.7610]]]), 's_image3': tensor([[[ 0.6029,  0.6164,  0.6298,  ..., -0.2029, -0.4715, -0.6461],\n",
      "         [ 0.6432,  0.6432,  0.6567,  ..., -0.2029, -0.4580, -0.6192],\n",
      "         [ 0.6970,  0.6970,  0.7104,  ..., -0.1894, -0.4312, -0.5789],\n",
      "         ...,\n",
      "         [-0.5923, -0.6058, -0.6192,  ...,  0.2403,  0.1732,  0.1195],\n",
      "         [-0.6729, -0.6192, -0.5386,  ..., -0.1626, -0.2163, -0.2566],\n",
      "         [-0.7266, -0.6326, -0.4983,  ..., -0.4312, -0.4715, -0.4849]],\n",
      "\n",
      "        [[ 0.6967,  0.7102,  0.7237,  ...,  0.0903, -0.1927, -0.3679],\n",
      "         [ 0.7371,  0.7371,  0.7506,  ...,  0.0903, -0.1792, -0.3544],\n",
      "         [ 0.7911,  0.7911,  0.8045,  ...,  0.0768, -0.1658, -0.3140],\n",
      "         ...,\n",
      "         [-0.7048, -0.7183, -0.7318,  ...,  0.0094, -0.0714, -0.1253],\n",
      "         [-0.7857, -0.7318, -0.6509,  ..., -0.3814, -0.4488, -0.4757],\n",
      "         [-0.8396, -0.7452, -0.6105,  ..., -0.6374, -0.6779, -0.6913]],\n",
      "\n",
      "        [[ 1.0227,  1.0358,  1.0489,  ...,  0.2751, -0.0134, -0.1971],\n",
      "         [ 1.0620,  1.0620,  1.0752,  ...,  0.2620, -0.0003, -0.1839],\n",
      "         [ 1.1145,  1.1145,  1.1276,  ...,  0.2489,  0.0128, -0.1446],\n",
      "         ...,\n",
      "         [-0.9053, -0.9184, -0.9315,  ..., -0.0397, -0.1184, -0.1708],\n",
      "         [-0.9840, -0.9315, -0.8528,  ..., -0.4200, -0.4725, -0.4987],\n",
      "         [-1.0365, -0.9447, -0.8135,  ..., -0.6561, -0.6955, -0.7086]]]), 'image3': tensor([[[ 0.1463,  0.3881,  0.5627,  ..., -0.6461, -0.6461, -0.6461],\n",
      "         [ 0.1463,  0.3881,  0.5627,  ..., -0.6461, -0.6461, -0.6461],\n",
      "         [ 0.1463,  0.3881,  0.5627,  ..., -0.6461, -0.6461, -0.6461],\n",
      "         ...,\n",
      "         [-0.1223,  0.1060,  0.2806,  ...,  0.9924,  0.9924,  1.0058],\n",
      "         [-0.2163, -0.0014,  0.1732,  ...,  0.9656,  1.0193,  1.0730],\n",
      "         [-0.2969, -0.0954,  0.0792,  ...,  0.6701,  0.7372,  0.8044]],\n",
      "\n",
      "        [[ 0.2655,  0.5215,  0.6967,  ..., -0.4892, -0.4892, -0.4892],\n",
      "         [ 0.2655,  0.5215,  0.6967,  ..., -0.4892, -0.4892, -0.4892],\n",
      "         [ 0.2655,  0.5215,  0.6967,  ..., -0.4892, -0.4892, -0.4892],\n",
      "         ...,\n",
      "         [-0.1523,  0.0633,  0.2251,  ...,  0.6293,  0.6159,  0.6428],\n",
      "         [-0.2601, -0.0579,  0.1038,  ...,  0.6159,  0.6563,  0.7237],\n",
      "         [-0.3544, -0.1658,  0.0094,  ...,  0.3463,  0.4137,  0.4811]],\n",
      "\n",
      "        [[ 0.5505,  0.8260,  1.0358,  ..., -0.3544, -0.3544, -0.3676],\n",
      "         [ 0.5505,  0.8260,  1.0358,  ..., -0.3544, -0.3544, -0.3676],\n",
      "         [ 0.5505,  0.8260,  1.0358,  ..., -0.3544, -0.3544, -0.3676],\n",
      "         ...,\n",
      "         [-0.1315,  0.0784,  0.2489,  ...,  0.5768,  0.5636,  0.5899],\n",
      "         [-0.2495, -0.0528,  0.1177,  ...,  0.5636,  0.6030,  0.6686],\n",
      "         [-0.3544, -0.1577, -0.0003,  ...,  0.3013,  0.3669,  0.4325]]]), 's_image2': tensor([[[-0.1760, -0.1626, -0.1626,  ...,  0.4418,  0.2538,  0.0657],\n",
      "         [-0.3909, -0.3775, -0.3775,  ...,  0.4686,  0.2806,  0.0792],\n",
      "         [-0.6192, -0.6058, -0.6058,  ...,  0.4821,  0.2941,  0.0926],\n",
      "         ...,\n",
      "         [-0.9818, -1.0355, -1.1027,  ...,  0.6701,  0.4686,  0.2538],\n",
      "         [-1.1027, -1.1161, -1.1564,  ...,  0.6701,  0.4686,  0.2538],\n",
      "         [-1.1833, -1.1698, -1.1698,  ...,  0.6701,  0.4686,  0.2538]],\n",
      "\n",
      "        [[-0.2062, -0.1927, -0.1927,  ...,  0.6832,  0.4811,  0.2655],\n",
      "         [-0.4083, -0.3949, -0.3949,  ...,  0.6832,  0.4811,  0.2655],\n",
      "         [-0.6239, -0.6105, -0.6105,  ...,  0.6698,  0.4676,  0.2520],\n",
      "         ...,\n",
      "         [-0.9609, -1.0148, -1.0821,  ...,  0.7776,  0.5620,  0.3463],\n",
      "         [-1.0956, -1.1091, -1.1360,  ...,  0.7776,  0.5620,  0.3463],\n",
      "         [-1.1765, -1.1630, -1.1630,  ...,  0.7776,  0.5620,  0.3463]],\n",
      "\n",
      "        [[-0.2495, -0.2495, -0.2495,  ...,  1.0883,  0.8522,  0.6030],\n",
      "         [-0.4200, -0.4069, -0.4069,  ...,  1.1145,  0.8653,  0.6161],\n",
      "         [-0.5774, -0.5643, -0.5643,  ...,  1.1276,  0.8784,  0.6292],\n",
      "         ...,\n",
      "         [-1.0758, -1.1152, -1.1676,  ...,  1.0620,  0.8260,  0.5768],\n",
      "         [-1.2070, -1.2070, -1.2332,  ...,  1.0620,  0.8260,  0.5768],\n",
      "         [-1.2857, -1.2594, -1.2594,  ...,  1.0620,  0.8260,  0.5768]]]), 't_image0': tensor([[[ 0.6701,  0.6835,  0.6835,  ..., -0.4580, -0.4580, -0.4715],\n",
      "         [ 0.6835,  0.6970,  0.6970,  ..., -0.4446, -0.4446, -0.4580],\n",
      "         [ 0.6835,  0.6970,  0.6970,  ..., -0.4312, -0.4312, -0.4446],\n",
      "         ...,\n",
      "         [-0.4849, -0.4849, -0.4715,  ..., -1.3444, -1.3310, -1.3176],\n",
      "         [-0.4849, -0.4849, -0.4715,  ..., -1.3444, -1.3310, -1.3176],\n",
      "         [-0.4715, -0.4715, -0.4580,  ..., -1.3444, -1.3444, -1.3310]],\n",
      "\n",
      "        [[ 0.7911,  0.7911,  0.7911,  ..., -0.3814, -0.3814, -0.3949],\n",
      "         [ 0.7911,  0.8045,  0.8045,  ..., -0.3679, -0.3679, -0.3814],\n",
      "         [ 0.7911,  0.8045,  0.8045,  ..., -0.3544, -0.3544, -0.3679],\n",
      "         ...,\n",
      "         [-0.4083, -0.4218, -0.4083,  ..., -1.3247, -1.3112, -1.2978],\n",
      "         [-0.4083, -0.4083, -0.4083,  ..., -1.3247, -1.3112, -1.2978],\n",
      "         [-0.3949, -0.3949, -0.3949,  ..., -1.3247, -1.3247, -1.3112]],\n",
      "\n",
      "        [[ 1.0752,  1.0752,  1.0752,  ..., -0.2364, -0.2364, -0.2495],\n",
      "         [ 1.0620,  1.0620,  1.0620,  ..., -0.2233, -0.2233, -0.2364],\n",
      "         [ 1.0489,  1.0620,  1.0620,  ..., -0.2233, -0.2233, -0.2364],\n",
      "         ...,\n",
      "         [-0.7741, -0.7741, -0.7610,  ..., -1.2988, -1.2857, -1.2725],\n",
      "         [-0.7741, -0.7741, -0.7610,  ..., -1.2988, -1.2857, -1.2725],\n",
      "         [-0.7741, -0.7741, -0.7610,  ..., -1.2988, -1.2988, -1.2857]]])}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "data_transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize(224),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.471, 0.460, 0.455], [0.292, 0.291, 0.299])\n",
    "            ])\n",
    "\n",
    "root_dir = '/home/xinsir/Pytorch/car_data'\n",
    "train_file = '/home/xinsir/Pytorch/car_data/train_list.txt'\n",
    "test_file = '/home/xinsir/Pytorch/car_data/test_list.txt'\n",
    "\n",
    "img_data = {'train': Bird_Dataset_Process(train_file, root_dir, train_vectors, 4, data_transform),\n",
    "                  'test': Bird_Test_Process(test_file, root_dir, test_vectors, 4, data_transform)}\n",
    "loader_img = {x: torch.utils.data.DataLoader(img_data[x], batch_size=20,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(img_data[x]) for x in ['train', 'test']}\n",
    "print(img_data['test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, resume=None):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    start_epoch = 0\n",
    "    if resume:\n",
    "        ckpt = torch.load(resume)\n",
    "        model = ckpt['best_model']\n",
    "        optimizer = ckpt['optimizer']\n",
    "        scheduler = ckpt['scheduler']       \n",
    "        start_epoch = ckpt['epoch']\n",
    "        \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            start_time = time.time()        \n",
    "            if epoch % 5 == 0 and phase == 'train':\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    lr = param_group['lr']\n",
    "                    print(\"***********************\")\n",
    "                    print(\"learning rate = %f\" % lr)\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for i_batch, sample_batched in enumerate(loader_img[phase]):\n",
    "                img0 = sample_batched['image0']\n",
    "                img1 = sample_batched['image1']\n",
    "                img2 = sample_batched['image2']\n",
    "                img3 = sample_batched['image3']\n",
    "                labels = sample_batched['label']\n",
    "                if phase == 'test':\n",
    "                    s_img0 = sample_batched['s_image0']\n",
    "                    s_img1 = sample_batched['s_image1']\n",
    "                    s_img2 = sample_batched['s_image2']\n",
    "                    s_img3 = sample_batched['s_image3']\n",
    "                    t_img0 = sample_batched['t_image0']\n",
    "                    t_img1 = sample_batched['t_image1']\n",
    "                    t_img2 = sample_batched['t_image2']\n",
    "                    t_img3 = sample_batched['t_image3']\n",
    "                    s_img0 = s_img0.to(device)\n",
    "                    s_img1 = s_img1.to(device)\n",
    "                    s_img2 = s_img2.to(device)\n",
    "                    s_img3 = s_img3.to(device)\n",
    "                    t_img0 = t_img0.to(device)\n",
    "                    t_img1 = t_img1.to(device)\n",
    "                    t_img2 = t_img2.to(device)\n",
    "                    t_img3 = t_img3.to(device)\n",
    "                    \n",
    "                img0 = img0.to(device)\n",
    "                img1 = img1.to(device)\n",
    "                img2 = img2.to(device)\n",
    "                img3 = img3.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if phase == 'train':\n",
    "                        output0 = model(img0)\n",
    "                        output1 = model(img1)\n",
    "                        output2 = model(img2)\n",
    "                        output3 = model(img3)\n",
    "                    else:\n",
    "                        output0 = (model(img0) + model(s_img0) + model(t_img0))/3.0\n",
    "                        output1 = (model(img1) + model(s_img1) + model(t_img1))/3.0\n",
    "                        output2 = (model(img2) + model(s_img2) + model(t_img2))/3.0\n",
    "                        output3 = (model(img3) + model(s_img3) + model(t_img3))/3.0\n",
    "                    outputs = output0 + output1 + output2 + output3\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * img3.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                if i_batch % 50 == 0 and phase == 'train':\n",
    "                    print(\"Iteration %d, loss = %f\" % (i_batch, loss))\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            if phase == 'test':\n",
    "                scheduler.step(epoch_loss)\n",
    "                \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            cost_time = (time.time() - start_time)/60.0\n",
    "            print('{} 1 epoch time: {:.2f}min'.format(\n",
    "                phase, cost_time))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'test_loss': epoch_loss,\n",
    "                    'test_acc': epoch_acc,\n",
    "                    'optimizer': optimizer,\n",
    "                    'scheduler': scheduler,\n",
    "                    'best_model': model},\n",
    "                    os.path.join('/home/xinsir/Pytorch/random_car/', '%03d.ckpt' % epoch))\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/89\n",
      "----------\n",
      "2018-12-21 14:22:08\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.001000\n",
      "Iteration 0, loss = 5.410166\n",
      "Iteration 50, loss = 5.321151\n",
      "Iteration 100, loss = 5.352105\n",
      "Iteration 150, loss = 5.310679\n",
      "Iteration 200, loss = 5.194160\n",
      "Iteration 250, loss = 5.348280\n",
      "Iteration 300, loss = 5.237159\n",
      "Iteration 350, loss = 5.301087\n",
      "Iteration 400, loss = 5.192891\n",
      "train Loss: 5.2982 Acc: 0.0081\n",
      "train 1 epoch time: 5.34min\n",
      "test Loss: 5.2051 Acc: 0.0179\n",
      "test 1 epoch time: 4.91min\n",
      "\n",
      "Epoch 1/89\n",
      "----------\n",
      "2018-12-21 14:32:23\n",
      "----------\n",
      "Iteration 0, loss = 5.225879\n",
      "Iteration 50, loss = 5.316267\n",
      "Iteration 100, loss = 5.251706\n",
      "Iteration 150, loss = 5.211287\n",
      "Iteration 200, loss = 5.503820\n",
      "Iteration 250, loss = 5.191754\n",
      "Iteration 300, loss = 4.858147\n",
      "Iteration 350, loss = 4.958974\n",
      "Iteration 400, loss = 4.896089\n",
      "train Loss: 5.1093 Acc: 0.0236\n",
      "train 1 epoch time: 5.35min\n",
      "test Loss: 4.7752 Acc: 0.0669\n",
      "test 1 epoch time: 4.88min\n",
      "\n",
      "Epoch 2/89\n",
      "----------\n",
      "2018-12-21 14:42:37\n",
      "----------\n",
      "Iteration 0, loss = 4.664184\n",
      "Iteration 50, loss = 4.870973\n",
      "Iteration 100, loss = 4.924312\n",
      "Iteration 150, loss = 5.165441\n",
      "Iteration 200, loss = 4.926177\n",
      "Iteration 250, loss = 4.822364\n",
      "Iteration 300, loss = 4.066752\n",
      "Iteration 350, loss = 3.874337\n",
      "Iteration 400, loss = 4.728786\n",
      "train Loss: 4.6534 Acc: 0.0608\n",
      "train 1 epoch time: 5.33min\n",
      "test Loss: 3.9787 Acc: 0.1775\n",
      "test 1 epoch time: 4.88min\n",
      "\n",
      "Epoch 3/89\n",
      "----------\n",
      "2018-12-21 14:52:50\n",
      "----------\n",
      "Iteration 0, loss = 4.204124\n",
      "Iteration 50, loss = 4.330548\n",
      "Iteration 100, loss = 4.361244\n",
      "Iteration 150, loss = 4.810466\n",
      "Iteration 200, loss = 3.599808\n",
      "Iteration 250, loss = 3.456273\n",
      "Iteration 300, loss = 3.181950\n",
      "Iteration 350, loss = 3.790190\n",
      "Iteration 400, loss = 4.187573\n",
      "train Loss: 4.0382 Acc: 0.1320\n",
      "train 1 epoch time: 5.34min\n",
      "test Loss: 3.2504 Acc: 0.3245\n",
      "test 1 epoch time: 4.88min\n",
      "\n",
      "Epoch 4/89\n",
      "----------\n",
      "2018-12-21 15:03:03\n",
      "----------\n",
      "Iteration 0, loss = 4.035918\n",
      "Iteration 50, loss = 3.811230\n",
      "Iteration 100, loss = 3.080942\n",
      "Iteration 150, loss = 2.966063\n",
      "Iteration 200, loss = 3.515533\n",
      "Iteration 250, loss = 3.712580\n",
      "Iteration 300, loss = 3.518193\n",
      "Iteration 350, loss = 2.519212\n",
      "Iteration 400, loss = 3.382959\n",
      "train Loss: 3.4137 Acc: 0.2205\n",
      "train 1 epoch time: 5.35min\n",
      "test Loss: 2.6653 Acc: 0.4366\n",
      "test 1 epoch time: 4.90min\n",
      "\n",
      "Epoch 5/89\n",
      "----------\n",
      "2018-12-21 15:13:19\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.001000\n",
      "Iteration 0, loss = 2.999337\n",
      "Iteration 50, loss = 3.775822\n",
      "Iteration 100, loss = 2.699652\n",
      "Iteration 150, loss = 3.288409\n",
      "Iteration 200, loss = 2.910067\n",
      "Iteration 250, loss = 3.248373\n",
      "Iteration 300, loss = 2.956220\n",
      "Iteration 350, loss = 3.040076\n",
      "Iteration 400, loss = 2.672379\n",
      "train Loss: 2.8840 Acc: 0.3099\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 1.9686 Acc: 0.5460\n",
      "test 1 epoch time: 4.71min\n",
      "\n",
      "Epoch 6/89\n",
      "----------\n",
      "2018-12-21 15:23:17\n",
      "----------\n",
      "Iteration 0, loss = 2.385856\n",
      "Iteration 50, loss = 3.352998\n",
      "Iteration 100, loss = 2.564682\n",
      "Iteration 150, loss = 3.159795\n",
      "Iteration 200, loss = 2.474851\n",
      "Iteration 250, loss = 2.186561\n",
      "Iteration 300, loss = 2.452665\n",
      "Iteration 350, loss = 1.835720\n",
      "Iteration 400, loss = 2.855896\n",
      "train Loss: 2.4493 Acc: 0.3996\n",
      "train 1 epoch time: 5.29min\n",
      "test Loss: 1.5835 Acc: 0.6457\n",
      "test 1 epoch time: 4.88min\n",
      "\n",
      "Epoch 7/89\n",
      "----------\n",
      "2018-12-21 15:33:28\n",
      "----------\n",
      "Iteration 0, loss = 2.338058\n",
      "Iteration 50, loss = 1.930723\n",
      "Iteration 100, loss = 2.352447\n",
      "Iteration 150, loss = 2.084080\n",
      "Iteration 200, loss = 1.755632\n",
      "Iteration 250, loss = 2.447771\n",
      "Iteration 300, loss = 2.073808\n",
      "Iteration 350, loss = 2.986279\n",
      "Iteration 400, loss = 1.973740\n",
      "train Loss: 2.0520 Acc: 0.4705\n",
      "train 1 epoch time: 5.36min\n",
      "test Loss: 1.5850 Acc: 0.6370\n",
      "test 1 epoch time: 4.88min\n",
      "\n",
      "Epoch 8/89\n",
      "----------\n",
      "2018-12-21 15:43:42\n",
      "----------\n",
      "Iteration 0, loss = 2.184526\n",
      "Iteration 50, loss = 1.824081\n",
      "Iteration 100, loss = 2.662487\n",
      "Iteration 150, loss = 2.138472\n",
      "Iteration 200, loss = 2.140241\n",
      "Iteration 250, loss = 2.179413\n",
      "Iteration 300, loss = 1.937538\n",
      "Iteration 350, loss = 2.207525\n",
      "Iteration 400, loss = 1.675869\n",
      "train Loss: 1.8471 Acc: 0.5172\n",
      "train 1 epoch time: 5.35min\n",
      "test Loss: 1.2939 Acc: 0.7012\n",
      "test 1 epoch time: 4.91min\n",
      "\n",
      "Epoch 9/89\n",
      "----------\n",
      "2018-12-21 15:53:57\n",
      "----------\n",
      "Iteration 0, loss = 1.290122\n",
      "Iteration 50, loss = 1.450520\n",
      "Iteration 100, loss = 1.828221\n",
      "Iteration 150, loss = 1.861644\n",
      "Iteration 200, loss = 1.901441\n",
      "Iteration 250, loss = 1.962426\n",
      "Iteration 300, loss = 1.433494\n",
      "Iteration 350, loss = 1.365051\n",
      "Iteration 400, loss = 1.659178\n",
      "train Loss: 1.6351 Acc: 0.5673\n",
      "train 1 epoch time: 5.37min\n",
      "test Loss: 1.0999 Acc: 0.7406\n",
      "test 1 epoch time: 4.90min\n",
      "\n",
      "Epoch 10/89\n",
      "----------\n",
      "2018-12-21 16:04:13\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.001000\n",
      "Iteration 0, loss = 1.565898\n",
      "Iteration 50, loss = 1.301506\n",
      "Iteration 100, loss = 1.818530\n",
      "Iteration 150, loss = 2.004624\n",
      "Iteration 200, loss = 1.155859\n",
      "Iteration 250, loss = 1.377694\n",
      "Iteration 300, loss = 1.559865\n",
      "Iteration 350, loss = 1.536900\n",
      "Iteration 400, loss = 0.980244\n",
      "train Loss: 1.4495 Acc: 0.6065\n",
      "train 1 epoch time: 5.34min\n",
      "test Loss: 0.9297 Acc: 0.7659\n",
      "test 1 epoch time: 4.89min\n",
      "\n",
      "Epoch 11/89\n",
      "----------\n",
      "2018-12-21 16:14:28\n",
      "----------\n",
      "Iteration 0, loss = 0.903522\n",
      "Iteration 50, loss = 0.882053\n",
      "Iteration 100, loss = 1.456321\n",
      "Iteration 150, loss = 1.271655\n",
      "Iteration 200, loss = 0.899511\n",
      "Iteration 250, loss = 1.036970\n",
      "Iteration 300, loss = 1.624490\n",
      "Iteration 350, loss = 1.418787\n",
      "Iteration 400, loss = 1.217049\n",
      "train Loss: 1.3147 Acc: 0.6396\n",
      "train 1 epoch time: 5.35min\n",
      "test Loss: 0.8967 Acc: 0.7786\n",
      "test 1 epoch time: 4.91min\n",
      "\n",
      "Epoch 12/89\n",
      "----------\n",
      "2018-12-21 16:24:44\n",
      "----------\n",
      "Iteration 0, loss = 1.521042\n",
      "Iteration 50, loss = 0.922417\n",
      "Iteration 100, loss = 1.105208\n",
      "Iteration 150, loss = 0.361881\n",
      "Iteration 200, loss = 1.322638\n",
      "Iteration 250, loss = 0.716107\n",
      "Iteration 300, loss = 1.271640\n",
      "Iteration 350, loss = 1.594598\n",
      "Iteration 400, loss = 1.621906\n",
      "train Loss: 1.1908 Acc: 0.6692\n",
      "train 1 epoch time: 5.35min\n",
      "test Loss: 0.9190 Acc: 0.7754\n",
      "test 1 epoch time: 4.89min\n",
      "\n",
      "Epoch 13/89\n",
      "----------\n",
      "2018-12-21 16:34:58\n",
      "----------\n",
      "Iteration 0, loss = 1.324884\n",
      "Iteration 50, loss = 0.287332\n",
      "Iteration 100, loss = 1.067267\n",
      "Iteration 150, loss = 1.090358\n",
      "Iteration 200, loss = 1.207748\n",
      "Iteration 250, loss = 1.017945\n",
      "Iteration 300, loss = 1.329141\n",
      "Iteration 350, loss = 0.750179\n",
      "Iteration 400, loss = 1.203688\n",
      "train Loss: 1.1056 Acc: 0.6945\n",
      "train 1 epoch time: 5.36min\n",
      "test Loss: 0.8197 Acc: 0.8018\n",
      "test 1 epoch time: 4.90min\n",
      "\n",
      "Epoch 14/89\n",
      "----------\n",
      "2018-12-21 16:45:14\n",
      "----------\n",
      "Iteration 0, loss = 1.124911\n",
      "Iteration 50, loss = 0.813508\n",
      "Iteration 100, loss = 1.881462\n",
      "Iteration 150, loss = 0.650226\n",
      "Iteration 200, loss = 1.333610\n",
      "Iteration 250, loss = 1.288885\n",
      "Iteration 300, loss = 1.566913\n",
      "Iteration 350, loss = 0.902629\n",
      "Iteration 400, loss = 0.600733\n",
      "train Loss: 1.0129 Acc: 0.7133\n",
      "train 1 epoch time: 5.30min\n",
      "test Loss: 0.7656 Acc: 0.8135\n",
      "test 1 epoch time: 4.72min\n",
      "\n",
      "Epoch 15/89\n",
      "----------\n",
      "2018-12-21 16:55:15\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.001000\n",
      "Iteration 0, loss = 0.701871\n",
      "Iteration 50, loss = 1.131481\n",
      "Iteration 100, loss = 0.801239\n",
      "Iteration 150, loss = 0.789642\n",
      "Iteration 200, loss = 0.924883\n",
      "Iteration 250, loss = 0.742756\n",
      "Iteration 300, loss = 1.322331\n",
      "Iteration 350, loss = 1.058877\n",
      "Iteration 400, loss = 0.870016\n",
      "train Loss: 0.9254 Acc: 0.7432\n",
      "train 1 epoch time: 5.28min\n",
      "test Loss: 0.7797 Acc: 0.8136\n",
      "test 1 epoch time: 4.71min\n",
      "\n",
      "Epoch 16/89\n",
      "----------\n",
      "2018-12-21 17:05:14\n",
      "----------\n",
      "Iteration 0, loss = 1.080823\n",
      "Iteration 50, loss = 0.544059\n",
      "Iteration 100, loss = 0.836865\n",
      "Iteration 150, loss = 0.794392\n",
      "Iteration 200, loss = 1.167328\n",
      "Iteration 250, loss = 0.958805\n",
      "Iteration 300, loss = 1.296795\n",
      "Iteration 350, loss = 1.467660\n",
      "Iteration 400, loss = 0.941799\n",
      "train Loss: 0.8713 Acc: 0.7510\n",
      "train 1 epoch time: 5.28min\n",
      "test Loss: 0.7589 Acc: 0.8098\n",
      "test 1 epoch time: 4.70min\n",
      "\n",
      "Epoch 17/89\n",
      "----------\n",
      "2018-12-21 17:15:13\n",
      "----------\n",
      "Iteration 0, loss = 1.183154\n",
      "Iteration 50, loss = 1.333349\n",
      "Iteration 100, loss = 0.376643\n",
      "Iteration 150, loss = 0.866457\n",
      "Iteration 200, loss = 1.301903\n",
      "Iteration 250, loss = 0.976858\n",
      "Iteration 300, loss = 0.900832\n",
      "Iteration 350, loss = 0.705842\n",
      "Iteration 400, loss = 0.669889\n",
      "train Loss: 0.8154 Acc: 0.7694\n",
      "train 1 epoch time: 5.29min\n",
      "test Loss: 0.6728 Acc: 0.8263\n",
      "test 1 epoch time: 4.71min\n",
      "\n",
      "Epoch 18/89\n",
      "----------\n",
      "2018-12-21 17:25:13\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.747882\n",
      "Iteration 50, loss = 0.954252\n",
      "Iteration 100, loss = 0.456934\n",
      "Iteration 150, loss = 0.875759\n",
      "Iteration 200, loss = 1.107138\n",
      "Iteration 250, loss = 0.651311\n",
      "Iteration 300, loss = 0.792954\n",
      "Iteration 350, loss = 1.192148\n",
      "Iteration 400, loss = 1.068950\n",
      "train Loss: 0.7682 Acc: 0.7797\n",
      "train 1 epoch time: 5.28min\n",
      "test Loss: 0.6699 Acc: 0.8261\n",
      "test 1 epoch time: 4.71min\n",
      "\n",
      "Epoch 19/89\n",
      "----------\n",
      "2018-12-21 17:35:12\n",
      "----------\n",
      "Iteration 0, loss = 0.702150\n",
      "Iteration 50, loss = 1.231266\n",
      "Iteration 100, loss = 0.536128\n",
      "Iteration 150, loss = 0.494306\n",
      "Iteration 200, loss = 0.941927\n",
      "Iteration 250, loss = 0.540256\n",
      "Iteration 300, loss = 0.917713\n",
      "Iteration 350, loss = 0.435223\n",
      "Iteration 400, loss = 0.724699\n",
      "train Loss: 0.7193 Acc: 0.7876\n",
      "train 1 epoch time: 5.28min\n",
      "test Loss: 0.7249 Acc: 0.8118\n",
      "test 1 epoch time: 4.71min\n",
      "\n",
      "Epoch 20/89\n",
      "----------\n",
      "2018-12-21 17:45:11\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.001000\n",
      "Iteration 0, loss = 0.408635\n",
      "Iteration 50, loss = 0.793189\n",
      "Iteration 100, loss = 0.884132\n",
      "Iteration 150, loss = 0.765964\n",
      "Iteration 200, loss = 0.988804\n",
      "Iteration 250, loss = 0.692224\n",
      "Iteration 300, loss = 0.843056\n",
      "Iteration 350, loss = 1.396215\n",
      "Iteration 400, loss = 0.636866\n",
      "train Loss: 0.6720 Acc: 0.8070\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.6360 Acc: 0.8365\n",
      "test 1 epoch time: 4.71min\n",
      "\n",
      "Epoch 21/89\n",
      "----------\n",
      "2018-12-21 17:55:10\n",
      "----------\n",
      "Iteration 0, loss = 0.601501\n",
      "Iteration 50, loss = 0.650684\n",
      "Iteration 100, loss = 0.562098\n",
      "Iteration 150, loss = 0.629630\n",
      "Iteration 200, loss = 0.606760\n",
      "Iteration 250, loss = 0.482741\n",
      "Iteration 300, loss = 0.275819\n",
      "Iteration 350, loss = 0.379962\n",
      "Iteration 400, loss = 0.611536\n",
      "train Loss: 0.6522 Acc: 0.8121\n",
      "train 1 epoch time: 5.28min\n",
      "test Loss: 0.6096 Acc: 0.8438\n",
      "test 1 epoch time: 4.72min\n",
      "\n",
      "Epoch 22/89\n",
      "----------\n",
      "2018-12-21 18:05:10\n",
      "----------\n",
      "Iteration 0, loss = 0.270632\n",
      "Iteration 50, loss = 0.896070\n",
      "Iteration 100, loss = 1.301346\n",
      "Iteration 150, loss = 0.346605\n",
      "Iteration 200, loss = 0.362630\n",
      "Iteration 250, loss = 0.448070\n",
      "Iteration 300, loss = 0.908865\n",
      "Iteration 350, loss = 0.795098\n",
      "Iteration 400, loss = 0.450458\n",
      "train Loss: 0.6259 Acc: 0.8142\n",
      "train 1 epoch time: 5.28min\n",
      "test Loss: 0.6078 Acc: 0.8467\n",
      "test 1 epoch time: 4.70min\n",
      "\n",
      "Epoch 23/89\n",
      "----------\n",
      "2018-12-21 18:15:09\n",
      "----------\n",
      "Iteration 0, loss = 0.945270\n",
      "Iteration 50, loss = 0.720039\n",
      "Iteration 100, loss = 0.435354\n",
      "Iteration 150, loss = 0.485200\n",
      "Iteration 200, loss = 0.218800\n",
      "Iteration 250, loss = 0.640887\n",
      "Iteration 300, loss = 0.344717\n",
      "Iteration 350, loss = 0.854336\n",
      "Iteration 400, loss = 0.272220\n",
      "train Loss: 0.5396 Acc: 0.8371\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.5603 Acc: 0.8576\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 24/89\n",
      "----------\n",
      "2018-12-21 18:25:05\n",
      "----------\n",
      "Iteration 0, loss = 0.180822\n",
      "Iteration 50, loss = 1.224140\n",
      "Iteration 100, loss = 0.407705\n",
      "Iteration 150, loss = 0.430497\n",
      "Iteration 200, loss = 0.325181\n",
      "Iteration 250, loss = 0.508600\n",
      "Iteration 300, loss = 0.157408\n",
      "Iteration 350, loss = 0.371473\n",
      "Iteration 400, loss = 0.709240\n",
      "train Loss: 0.5551 Acc: 0.8337\n",
      "train 1 epoch time: 5.23min\n",
      "test Loss: 0.6112 Acc: 0.8429\n",
      "test 1 epoch time: 4.69min\n",
      "\n",
      "Epoch 25/89\n",
      "----------\n",
      "2018-12-21 18:35:01\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.001000\n",
      "Iteration 0, loss = 0.200382\n",
      "Iteration 50, loss = 0.307790\n",
      "Iteration 100, loss = 0.345367\n",
      "Iteration 150, loss = 0.832540\n",
      "Iteration 200, loss = 0.306607\n",
      "Iteration 250, loss = 0.556966\n",
      "Iteration 300, loss = 0.915740\n",
      "Iteration 350, loss = 0.660802\n",
      "Iteration 400, loss = 0.694524\n",
      "train Loss: 0.5408 Acc: 0.8398\n",
      "train 1 epoch time: 5.25min\n",
      "test Loss: 0.6120 Acc: 0.8438\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 26/89\n",
      "----------\n",
      "2018-12-21 18:44:57\n",
      "----------\n",
      "Iteration 0, loss = 0.651895\n",
      "Iteration 50, loss = 0.804359\n",
      "Iteration 100, loss = 0.383964\n",
      "Iteration 150, loss = 0.383291\n",
      "Iteration 200, loss = 0.458463\n",
      "Iteration 250, loss = 0.554992\n",
      "Iteration 300, loss = 0.150924\n",
      "Iteration 350, loss = 0.757617\n",
      "Iteration 400, loss = 0.875530\n",
      "train Loss: 0.5140 Acc: 0.8468\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.5828 Acc: 0.8540\n",
      "test 1 epoch time: 4.69min\n",
      "\n",
      "Epoch 27/89\n",
      "----------\n",
      "2018-12-21 18:54:53\n",
      "----------\n",
      "Iteration 0, loss = 0.962880\n",
      "Iteration 50, loss = 0.265680\n",
      "Iteration 100, loss = 0.382950\n",
      "Iteration 150, loss = 0.529383\n",
      "Iteration 200, loss = 0.415362\n",
      "Iteration 250, loss = 0.475563\n",
      "Iteration 300, loss = 0.584953\n",
      "Iteration 350, loss = 0.397598\n",
      "Iteration 400, loss = 0.614299\n",
      "train Loss: 0.4758 Acc: 0.8556\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.5561 Acc: 0.8615\n",
      "test 1 epoch time: 4.69min\n",
      "\n",
      "Epoch 28/89\n",
      "----------\n",
      "2018-12-21 19:04:50\n",
      "----------\n",
      "Iteration 0, loss = 0.305466\n",
      "Iteration 50, loss = 0.152723\n",
      "Iteration 100, loss = 0.559471\n",
      "Iteration 150, loss = 0.374453\n",
      "Iteration 200, loss = 0.457003\n",
      "Iteration 250, loss = 0.241887\n",
      "Iteration 300, loss = 0.452682\n",
      "Iteration 350, loss = 0.746548\n",
      "Iteration 400, loss = 0.557727\n",
      "train Loss: 0.4560 Acc: 0.8668\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.5512 Acc: 0.8658\n",
      "test 1 epoch time: 4.69min\n",
      "\n",
      "Epoch 29/89\n",
      "----------\n",
      "2018-12-21 19:14:47\n",
      "----------\n",
      "Iteration 0, loss = 0.418154\n",
      "Iteration 50, loss = 0.535062\n",
      "Iteration 100, loss = 0.338122\n",
      "Iteration 150, loss = 0.458813\n",
      "Iteration 200, loss = 0.073235\n",
      "Iteration 250, loss = 0.852310\n",
      "Iteration 300, loss = 0.638193\n",
      "Iteration 350, loss = 0.569259\n",
      "Iteration 400, loss = 0.851536\n",
      "train Loss: 0.4542 Acc: 0.8639\n",
      "train 1 epoch time: 5.25min\n",
      "test Loss: 0.5728 Acc: 0.8541\n",
      "test 1 epoch time: 4.72min\n",
      "\n",
      "Epoch 30/89\n",
      "----------\n",
      "2018-12-21 19:24:45\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.001000\n",
      "Iteration 0, loss = 0.914637\n",
      "Iteration 50, loss = 0.294554\n",
      "Iteration 100, loss = 0.149187\n",
      "Iteration 150, loss = 0.096965\n",
      "Iteration 200, loss = 0.443132\n",
      "Iteration 250, loss = 0.636343\n",
      "Iteration 300, loss = 0.251699\n",
      "Iteration 350, loss = 0.570914\n",
      "Iteration 400, loss = 0.243088\n",
      "train Loss: 0.4287 Acc: 0.8725\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.5709 Acc: 0.8601\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 31/89\n",
      "----------\n",
      "2018-12-21 19:34:42\n",
      "----------\n",
      "Iteration 0, loss = 0.167654\n",
      "Iteration 50, loss = 0.380228\n",
      "Iteration 100, loss = 0.292188\n",
      "Iteration 150, loss = 0.218573\n",
      "Iteration 200, loss = 0.299610\n",
      "Iteration 250, loss = 0.214562\n",
      "Iteration 300, loss = 0.198341\n",
      "Iteration 350, loss = 0.364747\n",
      "Iteration 400, loss = 0.482435\n",
      "train Loss: 0.3995 Acc: 0.8789\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.5417 Acc: 0.8627\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 32/89\n",
      "----------\n",
      "2018-12-21 19:44:39\n",
      "----------\n",
      "Iteration 0, loss = 0.119694\n",
      "Iteration 50, loss = 0.148274\n",
      "Iteration 100, loss = 0.044509\n",
      "Iteration 150, loss = 0.557675\n",
      "Iteration 200, loss = 0.491794\n",
      "Iteration 250, loss = 0.355938\n",
      "Iteration 300, loss = 0.087545\n",
      "Iteration 350, loss = 0.837453\n",
      "Iteration 400, loss = 0.383311\n",
      "train Loss: 0.4033 Acc: 0.8786\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.5288 Acc: 0.8664\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 33/89\n",
      "----------\n",
      "2018-12-21 19:54:35\n",
      "----------\n",
      "Iteration 0, loss = 0.401359\n",
      "Iteration 50, loss = 0.181552\n",
      "Iteration 100, loss = 0.376310\n",
      "Iteration 150, loss = 0.180542\n",
      "Iteration 200, loss = 0.410685\n",
      "Iteration 250, loss = 0.347377\n",
      "Iteration 300, loss = 0.652288\n",
      "Iteration 350, loss = 0.332517\n",
      "Iteration 400, loss = 0.161570\n",
      "train Loss: 0.3704 Acc: 0.8867\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.5994 Acc: 0.8555\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 34/89\n",
      "----------\n",
      "2018-12-21 20:04:31\n",
      "----------\n",
      "Iteration 0, loss = 0.630742\n",
      "Iteration 50, loss = 0.228591\n",
      "Iteration 100, loss = 0.396015\n",
      "Iteration 150, loss = 0.293470\n",
      "Iteration 200, loss = 0.077603\n",
      "Iteration 250, loss = 0.459523\n",
      "Iteration 300, loss = 0.216474\n",
      "Iteration 350, loss = 0.472414\n",
      "Iteration 400, loss = 0.076421\n",
      "train Loss: 0.3458 Acc: 0.8916\n",
      "train 1 epoch time: 5.28min\n",
      "test Loss: 0.6006 Acc: 0.8550\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 35/89\n",
      "----------\n",
      "2018-12-21 20:14:29\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.001000\n",
      "Iteration 0, loss = 0.199544\n",
      "Iteration 50, loss = 0.198951\n",
      "Iteration 100, loss = 0.292347\n",
      "Iteration 150, loss = 0.364927\n",
      "Iteration 200, loss = 0.562882\n",
      "Iteration 250, loss = 0.254030\n",
      "Iteration 300, loss = 0.255230\n",
      "Iteration 350, loss = 0.537364\n",
      "Iteration 400, loss = 0.349567\n",
      "train Loss: 0.3658 Acc: 0.8884\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.5447 Acc: 0.8687\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 36/89\n",
      "----------\n",
      "2018-12-21 20:24:25\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.254793\n",
      "Iteration 50, loss = 0.587014\n",
      "Iteration 100, loss = 0.423203\n",
      "Iteration 150, loss = 0.225402\n",
      "Iteration 200, loss = 0.456930\n",
      "Iteration 250, loss = 0.606910\n",
      "Iteration 300, loss = 0.352579\n",
      "Iteration 350, loss = 0.592662\n",
      "Iteration 400, loss = 0.491774\n",
      "train Loss: 0.3415 Acc: 0.8962\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.5561 Acc: 0.8590\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 37/89\n",
      "----------\n",
      "2018-12-21 20:34:21\n",
      "----------\n",
      "Iteration 0, loss = 0.322195\n",
      "Iteration 50, loss = 0.440963\n",
      "Iteration 100, loss = 0.105577\n",
      "Iteration 150, loss = 0.455993\n",
      "Iteration 200, loss = 0.433855\n",
      "Iteration 250, loss = 0.284868\n",
      "Iteration 300, loss = 0.146530\n",
      "Iteration 350, loss = 0.208372\n",
      "Iteration 400, loss = 0.099165\n",
      "train Loss: 0.3404 Acc: 0.8972\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.5265 Acc: 0.8709\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 38/89\n",
      "----------\n",
      "2018-12-21 20:44:18\n",
      "----------\n",
      "Iteration 0, loss = 0.477413\n",
      "Iteration 50, loss = 0.536494\n",
      "Iteration 100, loss = 0.230595\n",
      "Iteration 150, loss = 0.134408\n",
      "Iteration 200, loss = 0.142114\n",
      "Iteration 250, loss = 0.457207\n",
      "Iteration 300, loss = 0.217625\n",
      "Iteration 350, loss = 0.293200\n",
      "Iteration 400, loss = 0.315807\n",
      "train Loss: 0.3164 Acc: 0.9025\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.6425 Acc: 0.8423\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 39/89\n",
      "----------\n",
      "2018-12-21 20:54:15\n",
      "----------\n",
      "Iteration 0, loss = 0.143006\n",
      "Iteration 50, loss = 0.695718\n",
      "Iteration 100, loss = 0.773812\n",
      "Iteration 150, loss = 0.873920\n",
      "Iteration 200, loss = 0.302190\n",
      "Iteration 250, loss = 0.169790\n",
      "Iteration 300, loss = 0.341029\n",
      "Iteration 350, loss = 0.274061\n",
      "Iteration 400, loss = 0.227158\n",
      "train Loss: 0.3187 Acc: 0.9004\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.5856 Acc: 0.8623\n",
      "test 1 epoch time: 4.69min\n",
      "\n",
      "Epoch 40/89\n",
      "----------\n",
      "2018-12-21 21:04:12\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.001000\n",
      "Iteration 0, loss = 0.041028\n",
      "Iteration 50, loss = 0.149530\n",
      "Iteration 100, loss = 0.851508\n",
      "Iteration 150, loss = 0.257214\n",
      "Iteration 200, loss = 0.781630\n",
      "Iteration 250, loss = 0.095294\n",
      "Iteration 300, loss = 0.492695\n",
      "Iteration 350, loss = 0.050621\n",
      "Iteration 400, loss = 0.638900\n",
      "train Loss: 0.3277 Acc: 0.8988\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.5015 Acc: 0.8791\n",
      "test 1 epoch time: 4.69min\n",
      "\n",
      "Epoch 41/89\n",
      "----------\n",
      "2018-12-21 21:14:10\n",
      "----------\n",
      "Iteration 0, loss = 0.135029\n",
      "Iteration 50, loss = 0.578190\n",
      "Iteration 100, loss = 0.116105\n",
      "Iteration 150, loss = 0.576329\n",
      "Iteration 200, loss = 0.207172\n",
      "Iteration 250, loss = 0.066112\n",
      "Iteration 300, loss = 0.114330\n",
      "Iteration 350, loss = 0.172254\n",
      "Iteration 400, loss = 0.109136\n",
      "train Loss: 0.2973 Acc: 0.9093\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.5505 Acc: 0.8633\n",
      "test 1 epoch time: 4.69min\n",
      "\n",
      "Epoch 42/89\n",
      "----------\n",
      "2018-12-21 21:24:07\n",
      "----------\n",
      "Iteration 0, loss = 0.423815\n",
      "Iteration 50, loss = 0.358728\n",
      "Iteration 100, loss = 0.185205\n",
      "Iteration 150, loss = 0.292648\n",
      "Iteration 200, loss = 0.385738\n",
      "Iteration 250, loss = 0.191708\n",
      "Iteration 300, loss = 0.262184\n",
      "Iteration 350, loss = 0.260523\n",
      "Iteration 400, loss = 0.065760\n",
      "train Loss: 0.2911 Acc: 0.9086\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.5177 Acc: 0.8753\n",
      "test 1 epoch time: 4.69min\n",
      "\n",
      "Epoch 43/89\n",
      "----------\n",
      "2018-12-21 21:34:04\n",
      "----------\n",
      "Iteration 0, loss = 0.461062\n",
      "Iteration 50, loss = 0.429620\n",
      "Iteration 100, loss = 0.204262\n",
      "Iteration 150, loss = 0.575327\n",
      "Iteration 200, loss = 0.130169\n",
      "Iteration 250, loss = 0.576717\n",
      "Iteration 300, loss = 0.254824\n",
      "Iteration 350, loss = 0.345502\n",
      "Iteration 400, loss = 0.284188\n",
      "train Loss: 0.2737 Acc: 0.9161\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.5170 Acc: 0.8756\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 44/89\n",
      "----------\n",
      "2018-12-21 21:44:01\n",
      "----------\n",
      "Iteration 0, loss = 0.168233\n",
      "Iteration 50, loss = 0.067982\n",
      "Iteration 100, loss = 0.263153\n",
      "Iteration 150, loss = 0.271876\n",
      "Iteration 200, loss = 0.212456\n",
      "Iteration 250, loss = 0.371887\n",
      "Iteration 300, loss = 0.244757\n",
      "Iteration 350, loss = 0.230971\n",
      "Iteration 400, loss = 0.260421\n",
      "train Loss: 0.2684 Acc: 0.9170\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.5410 Acc: 0.8582\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 45/89\n",
      "----------\n",
      "2018-12-21 21:53:57\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.001000\n",
      "Iteration 0, loss = 0.629063\n",
      "Iteration 50, loss = 0.357857\n",
      "Iteration 100, loss = 0.043288\n",
      "Iteration 150, loss = 0.037167\n",
      "Iteration 200, loss = 0.583009\n",
      "Iteration 250, loss = 0.318690\n",
      "Iteration 300, loss = 0.014886\n",
      "Iteration 350, loss = 0.090994\n",
      "Iteration 400, loss = 0.454273\n",
      "train Loss: 0.2619 Acc: 0.9187\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.5283 Acc: 0.8664\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 46/89\n",
      "----------\n",
      "2018-12-21 22:03:53\n",
      "----------\n",
      "Iteration 0, loss = 0.240132\n",
      "Iteration 50, loss = 0.021007\n",
      "Iteration 100, loss = 0.085286\n",
      "Iteration 150, loss = 0.047822\n",
      "Iteration 200, loss = 0.018814\n",
      "Iteration 250, loss = 0.081460\n",
      "Iteration 300, loss = 0.173895\n",
      "Iteration 350, loss = 0.086601\n",
      "Iteration 400, loss = 0.267943\n",
      "train Loss: 0.2511 Acc: 0.9218\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.5079 Acc: 0.8750\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 47/89\n",
      "----------\n",
      "2018-12-21 22:13:49\n",
      "----------\n",
      "Iteration 0, loss = 1.081003\n",
      "Iteration 50, loss = 0.169985\n",
      "Iteration 100, loss = 0.284541\n",
      "Iteration 150, loss = 0.223270\n",
      "Iteration 200, loss = 0.065015\n",
      "Iteration 250, loss = 0.296696\n",
      "Iteration 300, loss = 0.122510\n",
      "Iteration 350, loss = 0.167327\n",
      "Iteration 400, loss = 0.088329\n",
      "train Loss: 0.1812 Acc: 0.9439\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.4755 Acc: 0.8922\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 48/89\n",
      "----------\n",
      "2018-12-21 22:23:45\n",
      "----------\n",
      "Iteration 0, loss = 0.391244\n",
      "Iteration 50, loss = 0.154871\n",
      "Iteration 100, loss = 0.007059\n",
      "Iteration 150, loss = 0.036324\n",
      "Iteration 200, loss = 0.062130\n",
      "Iteration 250, loss = 0.225505\n",
      "Iteration 300, loss = 0.050472\n",
      "Iteration 350, loss = 0.173673\n",
      "Iteration 400, loss = 0.268941\n",
      "train Loss: 0.1604 Acc: 0.9490\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4928 Acc: 0.8924\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 49/89\n",
      "----------\n",
      "2018-12-21 22:33:41\n",
      "----------\n",
      "Iteration 0, loss = 0.022960\n",
      "Iteration 50, loss = 0.456411\n",
      "Iteration 100, loss = 0.069731\n",
      "Iteration 150, loss = 0.080878\n",
      "Iteration 200, loss = 0.206297\n",
      "Iteration 250, loss = 0.158676\n",
      "Iteration 300, loss = 0.434116\n",
      "Iteration 350, loss = 0.174467\n",
      "Iteration 400, loss = 0.057152\n",
      "train Loss: 0.1428 Acc: 0.9552\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4944 Acc: 0.8924\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 50/89\n",
      "----------\n",
      "2018-12-21 22:43:37\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000500\n",
      "Iteration 0, loss = 0.106204\n",
      "Iteration 50, loss = 0.211840\n",
      "Iteration 100, loss = 0.071523\n",
      "Iteration 150, loss = 0.022256\n",
      "Iteration 200, loss = 0.112208\n",
      "Iteration 250, loss = 0.009327\n",
      "Iteration 300, loss = 0.049750\n",
      "Iteration 350, loss = 0.074588\n",
      "Iteration 400, loss = 0.138300\n",
      "train Loss: 0.1321 Acc: 0.9556\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.5045 Acc: 0.8907\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 51/89\n",
      "----------\n",
      "2018-12-21 22:53:33\n",
      "----------\n",
      "Iteration 0, loss = 0.031877\n",
      "Iteration 50, loss = 0.458132\n",
      "Iteration 100, loss = 0.109959\n",
      "Iteration 150, loss = 0.242770\n",
      "Iteration 200, loss = 0.028261\n",
      "Iteration 250, loss = 0.259774\n",
      "Iteration 300, loss = 0.080796\n",
      "Iteration 350, loss = 0.215047\n",
      "Iteration 400, loss = 0.190405\n",
      "train Loss: 0.1417 Acc: 0.9571\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.5047 Acc: 0.8898\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 52/89\n",
      "----------\n",
      "2018-12-21 23:03:30\n",
      "----------\n",
      "Iteration 0, loss = 0.351373\n",
      "Iteration 50, loss = 0.011978\n",
      "Iteration 100, loss = 0.399268\n",
      "Iteration 150, loss = 0.100143\n",
      "Iteration 200, loss = 0.099074\n",
      "Iteration 250, loss = 0.324255\n",
      "Iteration 300, loss = 0.156998\n",
      "Iteration 350, loss = 0.122816\n",
      "Iteration 400, loss = 0.314247\n",
      "train Loss: 0.1379 Acc: 0.9549\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4762 Acc: 0.8962\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 53/89\n",
      "----------\n",
      "2018-12-21 23:13:26\n",
      "----------\n",
      "Iteration 0, loss = 0.176770\n",
      "Iteration 50, loss = 0.069135\n",
      "Iteration 100, loss = 0.155503\n",
      "Iteration 150, loss = 0.025380\n",
      "Iteration 200, loss = 0.187290\n",
      "Iteration 250, loss = 0.105287\n",
      "Iteration 300, loss = 0.315513\n",
      "Iteration 350, loss = 0.295080\n",
      "Iteration 400, loss = 0.064677\n",
      "train Loss: 0.1259 Acc: 0.9583\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.5135 Acc: 0.8924\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 54/89\n",
      "----------\n",
      "2018-12-21 23:23:23\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.013343\n",
      "Iteration 50, loss = 0.012587\n",
      "Iteration 100, loss = 0.018813\n",
      "Iteration 150, loss = 0.004026\n",
      "Iteration 200, loss = 0.035380\n",
      "Iteration 250, loss = 0.367415\n",
      "Iteration 300, loss = 0.020481\n",
      "Iteration 350, loss = 0.057164\n",
      "Iteration 400, loss = 0.180867\n",
      "train Loss: 0.1039 Acc: 0.9668\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4962 Acc: 0.8975\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 55/89\n",
      "----------\n",
      "2018-12-21 23:33:19\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000250\n",
      "Iteration 0, loss = 0.135867\n",
      "Iteration 50, loss = 0.412352\n",
      "Iteration 100, loss = 0.017862\n",
      "Iteration 150, loss = 0.562416\n",
      "Iteration 200, loss = 0.002212\n",
      "Iteration 250, loss = 0.066412\n",
      "Iteration 300, loss = 0.074483\n",
      "Iteration 350, loss = 0.089425\n",
      "Iteration 400, loss = 0.217265\n",
      "train Loss: 0.1023 Acc: 0.9686\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4802 Acc: 0.8969\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 56/89\n",
      "----------\n",
      "2018-12-21 23:43:15\n",
      "----------\n",
      "Iteration 0, loss = 0.259237\n",
      "Iteration 50, loss = 0.024315\n",
      "Iteration 100, loss = 0.217375\n",
      "Iteration 150, loss = 0.009443\n",
      "Iteration 200, loss = 0.178053\n",
      "Iteration 250, loss = 0.031885\n",
      "Iteration 300, loss = 0.081810\n",
      "Iteration 350, loss = 0.025163\n",
      "Iteration 400, loss = 0.011684\n",
      "train Loss: 0.0944 Acc: 0.9698\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4810 Acc: 0.8975\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 57/89\n",
      "----------\n",
      "2018-12-21 23:53:11\n",
      "----------\n",
      "Iteration 0, loss = 0.062304\n",
      "Iteration 50, loss = 0.076203\n",
      "Iteration 100, loss = 0.028526\n",
      "Iteration 150, loss = 0.015643\n",
      "Iteration 200, loss = 0.037512\n",
      "Iteration 250, loss = 0.003712\n",
      "Iteration 300, loss = 0.168262\n",
      "Iteration 350, loss = 0.118251\n",
      "Iteration 400, loss = 0.153611\n",
      "train Loss: 0.0864 Acc: 0.9721\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4975 Acc: 0.8986\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 58/89\n",
      "----------\n",
      "2018-12-22 00:03:07\n",
      "----------\n",
      "Iteration 0, loss = 0.034862\n",
      "Iteration 50, loss = 0.027623\n",
      "Iteration 100, loss = 0.060448\n",
      "Iteration 150, loss = 0.432667\n",
      "Iteration 200, loss = 0.154018\n",
      "Iteration 250, loss = 0.004914\n",
      "Iteration 300, loss = 0.017418\n",
      "Iteration 350, loss = 0.081226\n",
      "Iteration 400, loss = 0.026910\n",
      "train Loss: 0.0932 Acc: 0.9705\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4840 Acc: 0.8953\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 59/89\n",
      "----------\n",
      "2018-12-22 00:13:03\n",
      "----------\n",
      "Iteration 0, loss = 0.025844\n",
      "Iteration 50, loss = 0.202681\n",
      "Iteration 100, loss = 0.021466\n",
      "Iteration 150, loss = 0.015877\n",
      "Iteration 200, loss = 0.055508\n",
      "Iteration 250, loss = 0.087508\n",
      "Iteration 300, loss = 0.026230\n",
      "Iteration 350, loss = 0.078730\n",
      "Iteration 400, loss = 0.035566\n",
      "train Loss: 0.0971 Acc: 0.9691\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4876 Acc: 0.8955\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 60/89\n",
      "----------\n",
      "2018-12-22 00:22:59\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000125\n",
      "Iteration 0, loss = 0.017522\n",
      "Iteration 50, loss = 0.006063\n",
      "Iteration 100, loss = 0.095104\n",
      "Iteration 150, loss = 0.277530\n",
      "Iteration 200, loss = 0.093348\n",
      "Iteration 250, loss = 0.002547\n",
      "Iteration 300, loss = 0.041812\n",
      "Iteration 350, loss = 0.049791\n",
      "Iteration 400, loss = 0.062489\n",
      "train Loss: 0.0800 Acc: 0.9742\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.5003 Acc: 0.8996\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 61/89\n",
      "----------\n",
      "2018-12-22 00:32:56\n",
      "----------\n",
      "Iteration 0, loss = 0.091169\n",
      "Iteration 50, loss = 0.182366\n",
      "Iteration 100, loss = 0.194891\n",
      "Iteration 150, loss = 0.118078\n",
      "Iteration 200, loss = 0.042651\n",
      "Iteration 250, loss = 0.087810\n",
      "Iteration 300, loss = 0.002445\n",
      "Iteration 350, loss = 0.012830\n",
      "Iteration 400, loss = 0.249462\n",
      "train Loss: 0.0899 Acc: 0.9716\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.4922 Acc: 0.9030\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 62/89\n",
      "----------\n",
      "2018-12-22 00:42:54\n",
      "----------\n",
      "Iteration 0, loss = 0.190674\n",
      "Iteration 50, loss = 0.024785\n",
      "Iteration 100, loss = 0.070366\n",
      "Iteration 150, loss = 0.047110\n",
      "Iteration 200, loss = 0.101189\n",
      "Iteration 250, loss = 0.294311\n",
      "Iteration 300, loss = 0.016997\n",
      "Iteration 350, loss = 0.079089\n",
      "Iteration 400, loss = 0.237545\n",
      "train Loss: 0.0776 Acc: 0.9757\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.4916 Acc: 0.9030\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 63/89\n",
      "----------\n",
      "2018-12-22 00:52:51\n",
      "----------\n",
      "Iteration 0, loss = 0.010258\n",
      "Iteration 50, loss = 0.000715\n",
      "Iteration 100, loss = 0.144634\n",
      "Iteration 150, loss = 0.268777\n",
      "Iteration 200, loss = 0.210507\n",
      "Iteration 250, loss = 0.075023\n",
      "Iteration 300, loss = 0.045770\n",
      "Iteration 350, loss = 0.006523\n",
      "Iteration 400, loss = 0.223042\n",
      "train Loss: 0.0751 Acc: 0.9750\n",
      "train 1 epoch time: 5.29min\n",
      "test Loss: 0.4903 Acc: 0.9031\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 64/89\n",
      "----------\n",
      "2018-12-22 01:02:49\n",
      "----------\n",
      "Iteration 0, loss = 0.230840\n",
      "Iteration 50, loss = 0.127238\n",
      "Iteration 100, loss = 0.025115\n",
      "Iteration 150, loss = 0.012609\n",
      "Iteration 200, loss = 0.005479\n",
      "Iteration 250, loss = 0.081812\n",
      "Iteration 300, loss = 0.022076\n",
      "Iteration 350, loss = 0.026695\n",
      "Iteration 400, loss = 0.064311\n",
      "train Loss: 0.0783 Acc: 0.9740\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.4660 Acc: 0.9008\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 65/89\n",
      "----------\n",
      "2018-12-22 01:12:46\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000125\n",
      "Iteration 0, loss = 0.011954\n",
      "Iteration 50, loss = 0.000212\n",
      "Iteration 100, loss = 0.094606\n",
      "Iteration 150, loss = 0.007631\n",
      "Iteration 200, loss = 0.002808\n",
      "Iteration 250, loss = 0.027174\n",
      "Iteration 300, loss = 0.007118\n",
      "Iteration 350, loss = 0.003024\n",
      "Iteration 400, loss = 0.000897\n",
      "train Loss: 0.0658 Acc: 0.9799\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.4980 Acc: 0.9000\n",
      "test 1 epoch time: 4.69min\n",
      "\n",
      "Epoch 66/89\n",
      "----------\n",
      "2018-12-22 01:22:43\n",
      "----------\n",
      "Iteration 0, loss = 0.023588\n",
      "Iteration 50, loss = 0.005764\n",
      "Iteration 100, loss = 0.016581\n",
      "Iteration 150, loss = 0.080168\n",
      "Iteration 200, loss = 0.008282\n",
      "Iteration 250, loss = 0.012993\n",
      "Iteration 300, loss = 0.037546\n",
      "Iteration 350, loss = 0.102681\n",
      "Iteration 400, loss = 0.004528\n",
      "train Loss: 0.0746 Acc: 0.9763\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.5050 Acc: 0.9000\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 67/89\n",
      "----------\n",
      "2018-12-22 01:32:40\n",
      "----------\n",
      "Iteration 0, loss = 0.013389\n",
      "Iteration 50, loss = 0.066438\n",
      "Iteration 100, loss = 0.053704\n",
      "Iteration 150, loss = 0.140458\n",
      "Iteration 200, loss = 0.261487\n",
      "Iteration 250, loss = 0.010820\n",
      "Iteration 300, loss = 0.003849\n",
      "Iteration 350, loss = 0.299824\n",
      "Iteration 400, loss = 0.047382\n",
      "train Loss: 0.0683 Acc: 0.9780\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4883 Acc: 0.9024\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 68/89\n",
      "----------\n",
      "2018-12-22 01:42:36\n",
      "----------\n",
      "Iteration 0, loss = 0.008830\n",
      "Iteration 50, loss = 0.027424\n",
      "Iteration 100, loss = 0.000274\n",
      "Iteration 150, loss = 0.021426\n",
      "Iteration 200, loss = 0.134674\n",
      "Iteration 250, loss = 0.068511\n",
      "Iteration 300, loss = 0.022757\n",
      "Iteration 350, loss = 0.081657\n",
      "Iteration 400, loss = 0.250436\n",
      "train Loss: 0.0719 Acc: 0.9769\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4788 Acc: 0.9024\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 69/89\n",
      "----------\n",
      "2018-12-22 01:52:33\n",
      "----------\n",
      "Iteration 0, loss = 0.002629\n",
      "Iteration 50, loss = 0.055756\n",
      "Iteration 100, loss = 0.006332\n",
      "Iteration 150, loss = 0.237347\n",
      "Iteration 200, loss = 0.015431\n",
      "Iteration 250, loss = 0.015255\n",
      "Iteration 300, loss = 0.138400\n",
      "Iteration 350, loss = 0.017693\n",
      "Iteration 400, loss = 0.018850\n",
      "train Loss: 0.0742 Acc: 0.9770\n",
      "train 1 epoch time: 5.28min\n",
      "test Loss: 0.4773 Acc: 0.9032\n",
      "test 1 epoch time: 4.69min\n",
      "\n",
      "Epoch 70/89\n",
      "----------\n",
      "2018-12-22 02:02:32\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000125\n",
      "Iteration 0, loss = 0.024220\n",
      "Iteration 50, loss = 0.134091\n",
      "Iteration 100, loss = 0.010333\n",
      "Iteration 150, loss = 0.105577\n",
      "Iteration 200, loss = 0.135523\n",
      "Iteration 250, loss = 0.021364\n",
      "Iteration 300, loss = 0.057459\n",
      "Iteration 350, loss = 0.131292\n",
      "Iteration 400, loss = 0.018000\n",
      "train Loss: 0.0699 Acc: 0.9770\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.4795 Acc: 0.9046\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 71/89\n",
      "----------\n",
      "2018-12-22 02:12:29\n",
      "----------\n",
      "Iteration 0, loss = 0.194432\n",
      "Iteration 50, loss = 0.041372\n",
      "Iteration 100, loss = 0.008466\n",
      "Iteration 150, loss = 0.009767\n",
      "Iteration 200, loss = 0.033915\n",
      "Iteration 250, loss = 0.005721\n",
      "Iteration 300, loss = 0.172206\n",
      "Iteration 350, loss = 0.051181\n",
      "Iteration 400, loss = 0.078434\n",
      "train Loss: 0.0723 Acc: 0.9770\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4889 Acc: 0.9034\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 72/89\n",
      "----------\n",
      "2018-12-22 02:22:25\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.042829\n",
      "Iteration 50, loss = 0.013095\n",
      "Iteration 100, loss = 0.041023\n",
      "Iteration 150, loss = 0.214758\n",
      "Iteration 200, loss = 0.008015\n",
      "Iteration 250, loss = 0.042670\n",
      "Iteration 300, loss = 0.003710\n",
      "Iteration 350, loss = 0.097900\n",
      "Iteration 400, loss = 0.258823\n",
      "train Loss: 0.0755 Acc: 0.9762\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.4742 Acc: 0.9036\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 73/89\n",
      "----------\n",
      "2018-12-22 02:32:21\n",
      "----------\n",
      "Iteration 0, loss = 0.022643\n",
      "Iteration 50, loss = 0.101100\n",
      "Iteration 100, loss = 0.054008\n",
      "Iteration 150, loss = 0.081970\n",
      "Iteration 200, loss = 0.018893\n",
      "Iteration 250, loss = 0.050054\n",
      "Iteration 300, loss = 0.043128\n",
      "Iteration 350, loss = 0.012094\n",
      "Iteration 400, loss = 0.008237\n",
      "train Loss: 0.0647 Acc: 0.9815\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4770 Acc: 0.9056\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 74/89\n",
      "----------\n",
      "2018-12-22 02:42:18\n",
      "----------\n",
      "Iteration 0, loss = 0.046574\n",
      "Iteration 50, loss = 0.124376\n",
      "Iteration 100, loss = 0.207913\n",
      "Iteration 150, loss = 0.021505\n",
      "Iteration 200, loss = 0.024382\n",
      "Iteration 250, loss = 0.033890\n",
      "Iteration 300, loss = 0.003437\n",
      "Iteration 350, loss = 0.088956\n",
      "Iteration 400, loss = 0.271768\n",
      "train Loss: 0.0639 Acc: 0.9808\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4952 Acc: 0.9026\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 75/89\n",
      "----------\n",
      "2018-12-22 02:52:13\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000063\n",
      "Iteration 0, loss = 0.130724\n",
      "Iteration 50, loss = 0.006506\n",
      "Iteration 100, loss = 0.031878\n",
      "Iteration 150, loss = 0.006887\n",
      "Iteration 200, loss = 0.016740\n",
      "Iteration 250, loss = 0.007022\n",
      "Iteration 300, loss = 0.213110\n",
      "Iteration 350, loss = 0.100169\n",
      "Iteration 400, loss = 0.014709\n",
      "train Loss: 0.0610 Acc: 0.9813\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4876 Acc: 0.9025\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 76/89\n",
      "----------\n",
      "2018-12-22 03:02:09\n",
      "----------\n",
      "Iteration 0, loss = 0.084819\n",
      "Iteration 50, loss = 0.006063\n",
      "Iteration 100, loss = 0.015805\n",
      "Iteration 150, loss = 0.009071\n",
      "Iteration 200, loss = 0.025984\n",
      "Iteration 250, loss = 0.092966\n",
      "Iteration 300, loss = 0.018429\n",
      "Iteration 350, loss = 0.072191\n",
      "Iteration 400, loss = 0.084853\n",
      "train Loss: 0.0657 Acc: 0.9795\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4801 Acc: 0.9046\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 77/89\n",
      "----------\n",
      "2018-12-22 03:12:05\n",
      "----------\n",
      "Iteration 0, loss = 0.005207\n",
      "Iteration 50, loss = 0.085296\n",
      "Iteration 100, loss = 0.033668\n",
      "Iteration 150, loss = 0.103861\n",
      "Iteration 200, loss = 0.157322\n",
      "Iteration 250, loss = 0.087667\n",
      "Iteration 300, loss = 0.003992\n",
      "Iteration 350, loss = 0.031479\n",
      "Iteration 400, loss = 0.004697\n",
      "train Loss: 0.0620 Acc: 0.9784\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.4889 Acc: 0.9039\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 78/89\n",
      "----------\n",
      "2018-12-22 03:22:03\n",
      "----------\n",
      "Iteration 0, loss = 0.001020\n",
      "Iteration 50, loss = 0.042082\n",
      "Iteration 100, loss = 0.051444\n",
      "Iteration 150, loss = 0.358740\n",
      "Iteration 200, loss = 0.117923\n",
      "Iteration 250, loss = 0.003194\n",
      "Iteration 300, loss = 0.012540\n",
      "Iteration 350, loss = 0.009911\n",
      "Iteration 400, loss = 0.255937\n",
      "train Loss: 0.0616 Acc: 0.9791\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4823 Acc: 0.9060\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 79/89\n",
      "----------\n",
      "2018-12-22 03:31:59\n",
      "----------\n",
      "Iteration 0, loss = 0.013293\n",
      "Iteration 50, loss = 0.027558\n",
      "Iteration 100, loss = 0.139308\n",
      "Iteration 150, loss = 0.005114\n",
      "Iteration 200, loss = 0.082670\n",
      "Iteration 250, loss = 0.029163\n",
      "Iteration 300, loss = 0.030870\n",
      "Iteration 350, loss = 0.005814\n",
      "Iteration 400, loss = 0.009927\n",
      "train Loss: 0.0553 Acc: 0.9812\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4959 Acc: 0.9045\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 80/89\n",
      "----------\n",
      "2018-12-22 03:41:55\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000031\n",
      "Iteration 0, loss = 0.118546\n",
      "Iteration 50, loss = 0.105785\n",
      "Iteration 100, loss = 0.140272\n",
      "Iteration 150, loss = 0.003630\n",
      "Iteration 200, loss = 0.014319\n",
      "Iteration 250, loss = 0.013587\n",
      "Iteration 300, loss = 0.015220\n",
      "Iteration 350, loss = 0.242511\n",
      "Iteration 400, loss = 0.074108\n",
      "train Loss: 0.0665 Acc: 0.9794\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4936 Acc: 0.9031\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 81/89\n",
      "----------\n",
      "2018-12-22 03:51:51\n",
      "----------\n",
      "Iteration 0, loss = 0.103599\n",
      "Iteration 50, loss = 0.009194\n",
      "Iteration 100, loss = 0.031646\n",
      "Iteration 150, loss = 0.069497\n",
      "Iteration 200, loss = 0.229721\n",
      "Iteration 250, loss = 0.034137\n",
      "Iteration 300, loss = 0.031977\n",
      "Iteration 350, loss = 0.000317\n",
      "Iteration 400, loss = 0.005921\n",
      "train Loss: 0.0596 Acc: 0.9795\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4921 Acc: 0.9042\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 82/89\n",
      "----------\n",
      "2018-12-22 04:01:47\n",
      "----------\n",
      "Iteration 0, loss = 0.001400\n",
      "Iteration 50, loss = 0.015904\n",
      "Iteration 100, loss = 0.003877\n",
      "Iteration 150, loss = 0.024890\n",
      "Iteration 200, loss = 0.062835\n",
      "Iteration 250, loss = 0.003800\n",
      "Iteration 300, loss = 0.105425\n",
      "Iteration 350, loss = 0.060889\n",
      "Iteration 400, loss = 0.043711\n",
      "train Loss: 0.0541 Acc: 0.9822\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4970 Acc: 0.9031\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 83/89\n",
      "----------\n",
      "2018-12-22 04:11:43\n",
      "----------\n",
      "Iteration 0, loss = 0.011434\n",
      "Iteration 50, loss = 0.012527\n",
      "Iteration 100, loss = 0.001004\n",
      "Iteration 150, loss = 0.044978\n",
      "Iteration 200, loss = 0.004816\n",
      "Iteration 250, loss = 0.019817\n",
      "Iteration 300, loss = 0.007982\n",
      "Iteration 350, loss = 0.005098\n",
      "Iteration 400, loss = 0.044900\n",
      "train Loss: 0.0652 Acc: 0.9794\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4898 Acc: 0.9029\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 84/89\n",
      "----------\n",
      "2018-12-22 04:21:39\n",
      "----------\n",
      "Iteration 0, loss = 0.050542\n",
      "Iteration 50, loss = 0.004567\n",
      "Iteration 100, loss = 0.050454\n",
      "Iteration 150, loss = 0.140471\n",
      "Iteration 200, loss = 0.034346\n",
      "Iteration 250, loss = 0.060458\n",
      "Iteration 300, loss = 0.002607\n",
      "Iteration 350, loss = 0.035498\n",
      "Iteration 400, loss = 0.007406\n",
      "train Loss: 0.0581 Acc: 0.9824\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4856 Acc: 0.9049\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 85/89\n",
      "----------\n",
      "2018-12-22 04:31:35\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000016\n",
      "Iteration 0, loss = 0.008389\n",
      "Iteration 50, loss = 0.003687\n",
      "Iteration 100, loss = 0.007512\n",
      "Iteration 150, loss = 0.056916\n",
      "Iteration 200, loss = 0.002060\n",
      "Iteration 250, loss = 0.043930\n",
      "Iteration 300, loss = 0.374552\n",
      "Iteration 350, loss = 0.006227\n",
      "Iteration 400, loss = 0.026874\n",
      "train Loss: 0.0598 Acc: 0.9812\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4937 Acc: 0.9042\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 86/89\n",
      "----------\n",
      "2018-12-22 04:41:31\n",
      "----------\n",
      "Iteration 0, loss = 0.001322\n",
      "Iteration 50, loss = 0.051846\n",
      "Iteration 100, loss = 0.192628\n",
      "Iteration 150, loss = 0.094263\n",
      "Iteration 200, loss = 0.051939\n",
      "Iteration 250, loss = 0.041495\n",
      "Iteration 300, loss = 0.013699\n",
      "Iteration 350, loss = 0.003571\n",
      "Iteration 400, loss = 0.030350\n",
      "train Loss: 0.0613 Acc: 0.9792\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4924 Acc: 0.9029\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 87/89\n",
      "----------\n",
      "2018-12-22 04:51:28\n",
      "----------\n",
      "Iteration 0, loss = 0.115828\n",
      "Iteration 50, loss = 0.438172\n",
      "Iteration 100, loss = 0.173799\n",
      "Iteration 150, loss = 0.176598\n",
      "Iteration 200, loss = 0.430921\n",
      "Iteration 250, loss = 0.061176\n",
      "Iteration 300, loss = 0.002417\n",
      "Iteration 350, loss = 0.002072\n",
      "Iteration 400, loss = 0.060835\n",
      "train Loss: 0.0606 Acc: 0.9807\n",
      "train 1 epoch time: 5.27min\n",
      "test Loss: 0.4878 Acc: 0.9040\n",
      "test 1 epoch time: 4.67min\n",
      "\n",
      "Epoch 88/89\n",
      "----------\n",
      "2018-12-22 05:01:24\n",
      "----------\n",
      "Iteration 0, loss = 0.005512\n",
      "Iteration 50, loss = 0.001630\n",
      "Iteration 100, loss = 0.004144\n",
      "Iteration 150, loss = 0.034140\n",
      "Iteration 200, loss = 0.126334\n",
      "Iteration 250, loss = 0.185818\n",
      "Iteration 300, loss = 0.147773\n",
      "Iteration 350, loss = 0.066930\n",
      "Iteration 400, loss = 0.008346\n",
      "train Loss: 0.0577 Acc: 0.9816\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4973 Acc: 0.9044\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Epoch 89/89\n",
      "----------\n",
      "2018-12-22 05:11:21\n",
      "----------\n",
      "Iteration 0, loss = 0.015993\n",
      "Iteration 50, loss = 0.071164\n",
      "Iteration 100, loss = 0.083285\n",
      "Iteration 150, loss = 0.132900\n",
      "Iteration 200, loss = 0.207930\n",
      "Iteration 250, loss = 0.008350\n",
      "Iteration 300, loss = 0.024570\n",
      "Iteration 350, loss = 0.203189\n",
      "Iteration 400, loss = 0.003342\n",
      "train Loss: 0.0612 Acc: 0.9805\n",
      "train 1 epoch time: 5.26min\n",
      "test Loss: 0.4948 Acc: 0.9044\n",
      "test 1 epoch time: 4.68min\n",
      "\n",
      "Training complete in 899m 9s\n",
      "Best val Acc: 0.905982\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "import warnings\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "vgg_16 = models.vgg16(pretrained=True)\n",
    "vgg_16.classifier = nn.Sequential(*list(vgg_16.classifier.children())[:1])\n",
    "vgg_16.features[30] = nn.AvgPool2d(kernel_size=14, stride=1, padding=0)\n",
    "vgg_16.features.add_module('31', nn.Dropout(0.8)) \n",
    "vgg_16.classifier[0] = nn.Linear(in_features=512, out_features=200, bias=True)\n",
    "# vgg_16 = nn.DataParallel(vgg_16, device_ids=[2, 3])\n",
    "vgg_16 = vgg_16.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(vgg_16.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "model = train_model(vgg_16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=90)\n",
    "                    # resume='/home/xinsir/Pytorch/random_car/006.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '/home/xinsir/Pytorch/random_part_car')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
