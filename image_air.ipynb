{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization completed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, transform\n",
    "\n",
    "print (\"initialization completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bird_Dataset_Process(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, train_file, root_dir, transform=None):\n",
    "        f = open(train_file, 'r')\n",
    "        self.train_list = f.readlines()\n",
    "        f.close()\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        line = self.train_list[idx]\n",
    "        img_dir_label = line.strip('\\n').split(' ')\n",
    "        img_dir = os.path.join(self.root_dir, img_dir_label[0])\n",
    "        image = io.imread(img_dir)\n",
    "        if len(image.shape) == 2:\n",
    "            image = image[:,:,np.newaxis]\n",
    "            image = np.tile(image, [1, 1, 3])\n",
    "        label = int(img_dir_label[1])\n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Bird_Dataset_Process'>\n",
      "torch.Size([3, 448, 448])\n",
      "6667\n",
      "{'test': 3333, 'train': 6667}\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize([448, 448]),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),   \n",
    "        transforms.Normalize([0.480, 0.511, 0.534], [0.221, 0.215, 0.246])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize([448, 448]),\n",
    "        transforms.CenterCrop(448),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.480, 0.511, 0.534], [0.221, 0.215, 0.246])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "root_dir = '/home/xinsir/Pytorch/air_data/'\n",
    "train_file = '/home/xinsir/Pytorch/air_data/train_list.txt'\n",
    "test_file = '/home/xinsir/Pytorch/air_data/test_list.txt'\n",
    "image_datasets = {'train': Bird_Dataset_Process(train_file, root_dir, data_transforms['train']),\n",
    "                  'test': Bird_Dataset_Process(test_file, root_dir, data_transforms['test'])}\n",
    "\n",
    "print(type(image_datasets['train']))\n",
    "print(image_datasets['train'][0]['image'].shape)\n",
    "print(len(image_datasets['train']))\n",
    "\n",
    "train_dataset = image_datasets['train']\n",
    "test_dataset = image_datasets['test']\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'test']}\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "\n",
    "print(dataset_sizes)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_matrix = torch.Tensor(6667, 3, 448, 448)\n",
    "# print(train_matrix.shape)\n",
    "# for i in range(len(train_dataset)):\n",
    "#     print(i)\n",
    "#     train_matrix[i] = train_dataset[i]['image']\n",
    "# R = np.mean(train_matrix[:, 0, :, :].numpy().flat)\n",
    "# G = np.mean(train_matrix[:, 1, :, :].numpy().flat)\n",
    "# B = np.mean(train_matrix[:, 2, :, :].numpy().flat)\n",
    "# R_std = np.std(train_matrix[:, 0, :, :].numpy().flat)\n",
    "# G_std = np.std(train_matrix[:, 1, :, :].numpy().flat)\n",
    "# B_std = np.std(train_matrix[:, 2, :, :].numpy().flat)\n",
    "# print(R, G, B, R_std, G_std, B_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "                \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            start_time = time.time()        \n",
    "            if epoch % 5 == 0 and phase == 'train':\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    lr = param_group['lr']\n",
    "                    print(\"***********************\")\n",
    "                    print(\"learning rate = %f\" % lr)\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for i_batch, sample_batched in enumerate(dataloaders[phase]):\n",
    "                inputs = sample_batched['image']\n",
    "                labels = sample_batched['label']\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                if i_batch % 50 == 0 and phase == 'train':\n",
    "                    print(\"Iteration %d, loss = %f\" % (i_batch, loss))\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            if phase == 'test':\n",
    "                scheduler.step(epoch_loss)\n",
    "                \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            cost_time = (time.time() - start_time)/60.0\n",
    "            print('{} 1 epoch time: {:.2f}min'.format(\n",
    "                phase, cost_time))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "test Loss: 0.6541 Acc: 0.8668\n",
      "test 1 epoch time: 0.64min\n",
      "\n",
      "Training complete in 0m 38s\n",
      "Best val Acc: 0.866787\n"
     ]
    }
   ],
   "source": [
    "vgg_16 = models.vgg16(pretrained=True)\n",
    "\n",
    "\n",
    "vgg_16.classifier = nn.Sequential(*list(vgg_16.classifier.children())[:1])\n",
    "vgg_16.features[30] = nn.AvgPool2d(kernel_size=28, stride=1, padding=0)\n",
    "vgg_16.features.add_module('31', nn.Dropout(0.8)) \n",
    "vgg_16.classifier[0] = nn.Linear(in_features=512, out_features=200, bias=True)\n",
    "\n",
    "# vgg_16 = torch.load('/home/xinsir/Pytorch/aircraft_vgg16')\n",
    "vgg_16 = vgg_16.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "# optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "optimizer_ft = optim.SGD(vgg_16.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, mode='min', factor=0.5, patience=10)\n",
    "\n",
    "model_best = train_model(vgg_16, criterion, optimizer_ft,\n",
    "                         exp_lr_scheduler, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_best, '/home/xinsir/Pytorch/aircraft_vgg16_0.9_86.7%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
